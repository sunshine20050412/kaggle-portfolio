# ğŸˆ NFL Big Data Bowl 2026 â€” Prediction Track

> **åŸºäºç‰©ç†å…ˆéªŒä¸ GRU åºåˆ—å»ºæ¨¡çš„ NFL ä¼ çƒé˜¶æ®µ 22 äººè½¨è¿¹é¢„æµ‹**
>
> **Predicting 22-player trajectories during ball-in-air phase using physics-informed geometric priors and GRU sequence modeling**
>
> Kaggle Competition Â· Nov 2025 â€“ Jan 2026

[![Python](https://img.shields.io/badge/Python-3.10-blue.svg)](https://python.org)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.1-red.svg)](https://pytorch.org)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Kaggle](https://img.shields.io/badge/Kaggle-Silver_Medal_ğŸ¥ˆ-silver.svg)](https://www.kaggle.com/competitions/nfl-big-data-bowl-2026-prediction)

**ğŸŒ Language / è¯­è¨€ï¼šæœ¬æ–‡æ¡£ä¸ºä¸­è‹±æ–‡å¯¹ç…§ç‰ˆ â€” This document is bilingual (Chinese & English)**

---

## âœ… èµ›äº‹éªŒè¯ / Competition Verification

> ä»¥ä¸‹é“¾æ¥å‡å¯å…¬å¼€è®¿é—®ï¼Œå®¡é˜…è€…å¯è‡ªè¡Œæ ¸å®èµ›äº‹çœŸå®æ€§ã€èµ›é¢˜å†…å®¹åŠæ’è¡Œæ¦œã€‚
>
> All links below are publicly accessible. Reviewers can independently verify the competition, task, and leaderboard.

| é¡¹ç›® / Item | é“¾æ¥ / Link |
|---|---|
| **ğŸ† æ¯”èµ›ä¸»é¡µ / Competition Page** | [kaggle.com/competitions/nfl-big-data-bowl-2026-prediction](https://www.kaggle.com/competitions/nfl-big-data-bowl-2026-prediction) |
| **ğŸ“Š æ•°æ®è¯´æ˜ / Data Description** | [kaggle.com/.../data](https://www.kaggle.com/competitions/nfl-big-data-bowl-2026-prediction/data) |
| **ğŸ“ˆ å…¬å¼€æ’è¡Œæ¦œ / Public Leaderboard** | [kaggle.com/.../leaderboard](https://www.kaggle.com/competitions/nfl-big-data-bowl-2026-prediction/leaderboard) |
| **ğŸˆ NFL å®˜æ–¹å…¬å‘Š / NFL Official Announcement** | [operations.nfl.com/.../big-data-bowl](https://operations.nfl.com/updates/football-ops/nfl-announces-eighth-annual-big-data-bowl-powered-by-aws/) |
| **ğŸ‘¤ æˆ‘çš„ Kaggle ä¸»é¡µ / My Kaggle Profile** | https://www.kaggle.com/after456987321 |

### èµ›äº‹æ ¸å¿ƒä¿¡æ¯ / Competition Key Facts

| é¡¹ç›® / Item | è¯¦æƒ… / Details |
|---|---|
| ä¸»åŠæ–¹ / Organizer | **NFL Football Operations**ï¼Œç”± **AWS** èµåŠ©ï¼Œ**Kaggle** æ‰¿åŠï¼ˆç¬¬ 8 å±Šï¼‰ / NFL Football Operations, powered by AWS, hosted on Kaggle (8th annual) |
| å¥–é‡‘ / Prize | é¢„æµ‹èµ›é“ **$50,000** / $50,000 for prediction track |
| å‚èµ›æ•°æ® / Training Data | 2023â€“2024 èµ›å­£ NFL Next Gen Stats è¿½è¸ªæ•°æ®ï¼ˆ10 Hzï¼‰/ 2023â€“2024 NFL seasons, NGS tracking at 10 Hz |
| æµ‹è¯•è¯„ä¼° / Test Evaluation | å¯¹ **2025 èµ›å­£ Weeks 14â€“18** çš„çœŸå®æ¯”èµ›è¿›è¡Œå®æ—¶è¯„ä¼° / Live evaluation against 2025 season (Weeks 14â€“18) |
| è¯„ä¼°æŒ‡æ ‡ / Metric | æ‰€æœ‰é¢„æµ‹åæ ‡çš„ **RMSE** / RMSE over all predicted (x, y) coordinates |
| æ—¶é—´çº¿ / Timeline | æ³¨å†Œ 2025.09.25 â†’ æˆªæ­¢ 2025.11.26 â†’ å†³èµ›è€…åœ¨ **2026 NFL Scouting Combine** ç°åœºå±•ç¤º / Registration Sep 25 â†’ Deadline Nov 26 â†’ Finalists present at NFL Combine (Feb 23 â€“ Mar 2, 2026) |
| æˆ‘çš„æˆç»© / My Result | ğŸ¥ˆ **Silver Medal â€” 52nd / 772 teams (Top 6.7%)** |

---

## ğŸ“Œ é¡¹ç›®æ¦‚è¿° / Project Summary

### æ ¸å¿ƒæ€è·¯ / Core Idea

ä¸è®©æ¨¡å‹ä»é›¶å­¦è½¨è¿¹ï¼Œè€Œæ˜¯å…ˆç”¨è§„åˆ™æ„é€ "å‡ ä½•ç»ˆç‚¹åŸºçº¿"ï¼ˆæ¥çƒæ‰‹â†’è½ç‚¹ã€é˜²å®ˆè€…â†’é•œåƒåç§»ã€å…¶ä»–â†’åŒ€é€Ÿå¤–æ¨ï¼‰ï¼Œå†ç”¨ GRU å­¦ä¹ æ®‹å·®ä¿®æ­£ã€‚è¿™ä¸€å…ˆéªŒæ³¨å…¥æ˜¯å…¨æ–¹æ¡ˆä¸­ RMSE æ”¹å–„æœ€å¤§çš„å•ä¸€å› ç´ ã€‚

Instead of learning trajectories from scratch, I first construct a rule-based "Geometric Endpoint Baseline" per player role (receiver â†’ landing point; defender â†’ mirror offset; others â†’ constant-velocity extrapolation), then train a GRU to learn residual corrections. This prior injection was the single largest RMSE improvement in the entire solution.

### ä¸»è¦æ”¶è· / Key Takeaways

- **è¾“å‡ºè¡¨ç¤º > æ¨¡å‹æ¶æ„** â€” ç»å¯¹åæ ‡â†’é€æ­¥å¢é‡çš„åˆ‡æ¢ï¼ŒRMSE æ”¹å–„ 20â€“30%ï¼Œè¿œè¶…æ¨¡å‹é€‰å‹çš„å½±å“
- **Output representation > model architecture** â€” Switching from absolute coords to delta + cumsum yielded ~20â€“30% RMSE gain, far exceeding any architecture change
- **é¢†åŸŸå…ˆéªŒéœ€è¦ç½®ä¿¡åº¦é—¨æ§** â€” é˜²å®ˆè€…é•œåƒåŒ¹é…åœ¨äººç›¯äººé˜²å®ˆä¸­æœ‰æ•ˆï¼Œä½†åœ¨åŒºåŸŸé˜²å®ˆä¸­å¼•å…¥å™ªå£°
- **Domain priors need confidence gates** â€” Mirror-receiver matching works for man coverage but introduces noise in zone defense
- **å¼‚å¸¸å¥½çš„æŒ‡æ ‡ = æ³„æ¼ä¿¡å·** â€” é€šè¿‡è¿½æŸ¥å¼‚å¸¸ä½çš„éªŒè¯æŸå¤±ï¼Œå‘ç°å¹¶ä¿®å¤äº†äº¤å‰éªŒè¯åˆ†ç»„é”™è¯¯
- **Anomalously good metrics = leakage signal** â€” Tracking suspiciously low val loss led to discovering and fixing a CV grouping bug

---

## ğŸ“‹ ç›®å½• / Table of Contents

- [èµ›äº‹éªŒè¯ / Competition Verification](#-èµ›äº‹éªŒè¯--competition-verification)
- [é¡¹ç›®æ¦‚è¿° / Project Summary](#-é¡¹ç›®æ¦‚è¿°--project-summary)
- [èµ›é¢˜èƒŒæ™¯ / Competition Background](#-èµ›é¢˜èƒŒæ™¯--competition-background)
- [æ–¹æ¡ˆæ¦‚è§ˆ / Solution Overview](#-æ–¹æ¡ˆæ¦‚è§ˆ--solution-overview)
- [æ ¸å¿ƒåˆ›æ–°ï¼šå‡ ä½•ç»ˆç‚¹åŸºçº¿ / Core Innovation](#-æ ¸å¿ƒåˆ›æ–°å‡ ä½•ç»ˆç‚¹åŸºçº¿--core-innovation-geometric-endpoint-baseline)
- [æŠ€æœ¯æ¶æ„ / Technical Architecture](#-æŠ€æœ¯æ¶æ„--technical-architecture)
- [å…³é”®å·¥ç¨‹æŒ‘æˆ˜ä¸è§£å†³ / Engineering Challenges](#-å…³é”®å·¥ç¨‹æŒ‘æˆ˜ä¸è§£å†³--key-engineering-challenges--solutions)
- [ç»“æœä¸æ¶ˆèå®éªŒ / Results & Ablation](#-ç»“æœä¸æ¶ˆèå®éªŒ--results--ablation)
- [ä»“åº“ç»“æ„ä¸èµ›é¢˜å¯¹é½ / Repository Structure & Competition Alignment](#-ä»“åº“ç»“æ„ä¸èµ›é¢˜å¯¹é½--repository-structure--competition-alignment)
- [å¤ç°æŒ‡å— / Reproduction Guide](#-å¤ç°æŒ‡å—--reproduction-guide)
- [åæ€ã€ä¸è¶³ä¸æœªæ¥æ–¹å‘ / Reflections & Future Directions](#-åæ€ä¸è¶³ä¸æœªæ¥æ–¹å‘--reflections-limitations--future-directions)

---

## ğŸŸ èµ›é¢˜èƒŒæ™¯ / Competition Background

**ä¸­æ–‡ï¼š**
åœ¨ NFL ä¼ çƒè¿›æ”»ä¸­ï¼Œå››åˆ†å«å‡ºæ‰‹çš„ç¬é—´å¼€å¯äº†æ¯”èµ›ä¸­æœ€ä¸ç¡®å®šçš„é˜¶æ®µâ€”â€”**çƒåœ¨ç©ºä¸­æœŸ**ï¼ˆé€šå¸¸ 1â€“9 ç§’ï¼‰ã€‚åœ¨æ­¤çª—å£å†…ï¼Œ22 åçƒå‘˜åŒæ—¶åšå‡ºååº”ï¼šæ¥çƒæ‰‹æœè½ç‚¹æ±‡èšï¼Œé˜²å®ˆè€…è¿½è¸ªç›¯é˜²ç›®æ ‡ï¼Œå…¶ä½™çƒå‘˜ä¾æ®æˆ˜æœ¯è°ƒæ•´ä½ç½®ã€‚

èµ›é¢˜è¦æ±‚ï¼šç»™å®šå‡ºæ‰‹å‰ 10 Hz è¿½è¸ªåºåˆ—ï¼ˆæˆªæ­¢åˆ°å‡ºæ‰‹å¸§ï¼‰ã€ç›®æ ‡æ¥çƒæ‰‹èº«ä»½å’Œæ©„æ¦„çƒè½ç‚¹ï¼Œé¢„æµ‹çƒåœ¨ç©ºä¸­æœŸé—´æ¯åçƒå‘˜æ¯å¸§çš„ (x, y) åæ ‡ã€‚è¯„ä¼°æŒ‡æ ‡ä¸ºæ‰€æœ‰é¢„æµ‹åæ ‡çš„ RMSEã€‚

**English:**
In NFL passing plays, the quarterback's release creates the most uncertain phase â€” the **ball-in-air period** (typically 1â€“9 seconds). All 22 players react simultaneously: receivers converge on the landing spot, defenders track assignments, and others adjust in real time.

The task: given pre-throw 10 Hz tracking sequences (cut off at release), the targeted receiver identity, and the ball landing point, predict each player's (x, y) at every future frame until ball arrival. Evaluated by RMSE.

**ä¸»è¦æŒ‘æˆ˜ / Key Challengesï¼š**

| æŒ‘æˆ˜ / Challenge | è¯´æ˜ / Description |
|---|---|
| å˜é•¿è¾“å‡º / Variable-length output | æ¯åçƒå‘˜éœ€é¢„æµ‹ 1â€“94 å¸§ / 1â€“94 frames per player |
| å¤šæ™ºèƒ½ä½“äº¤äº’ / Multi-agent interaction | 22 äººè¿åŠ¨ç›¸äº’ä¾èµ– / 22 players' movements are interdependent |
| è§’è‰²å·®å¼‚ / Role-dependent patterns | æ¥çƒæ‰‹ã€é˜²å®ˆè€…ã€æ‹¦æˆªè€…åŠ¨æ€æ¨¡å¼æˆªç„¶ä¸åŒ / Receivers, defenders, blockers follow different dynamics |
| é•¿æ—¶é¢„æµ‹ / Long-horizon prediction | æœ€é•¿ 9.4 ç§’ï¼ˆ94 å¸§ï¼‰/ Up to 9.4 seconds at 10 Hz |

---

## ğŸŒŸ æ–¹æ¡ˆæ¦‚è§ˆ / Solution Overview

```
æ ¸å¿ƒæ´å¯Ÿ / Key Insight:
  ä¸è®©æ¨¡å‹ä»é›¶å­¦è½¨è¿¹ï¼Œå…ˆç»™ä¸€ä¸ª"åˆç†çŒœæµ‹"ï¼Œå†å­¦ä¿®æ­£ã€‚
  Don't learn trajectories from scratch â€” give a reasonable guess first, then learn corrections.
```

| ç»„ä»¶ / Component | æ–¹æ³• / Approach |
|---|---|
| **æ ¸å¿ƒåˆ›æ–° / Core Innovation** | å‡ ä½•ç»ˆç‚¹åŸºçº¿â€”â€”æŒ‰è§’è‰²è§„åˆ™ç”Ÿæˆç›®æ ‡ç‚¹ / Geometric Endpoint Baseline â€” rule-based target per role |
| **ç‰¹å¾ / Features** | 167 ç»´ï¼Œè¦†ç›– 8 ç»„ï¼ˆè§ä¸‹å›¾ï¼‰/ 167 dims across 8 groups (see diagrams below) |
| **æ¨¡å‹ / Model** | 2 å±‚ GRU â†’ å¯å­¦ä¹ æŸ¥è¯¢æ³¨æ„åŠ›æ± åŒ– â†’ MLP å¤´ / 2-layer GRU â†’ Learnable-Query Attention Pooling â†’ MLP Head |
| **è¾“å‡º / Output** | é€æ­¥å¢é‡ â†’ `cumsum` å½¢æˆç´¯ç§¯ä½ç§» / Per-step deltas â†’ `cumsum` for cumulative displacement |
| **æŸå¤±å‡½æ•° / Loss** | æ—¶é—´è¡°å‡ Huber æŸå¤± / Temporal Huber with exponential time-decay |
| **éªŒè¯ / Validation** | æŒ‰ `game_id` åˆ†ç»„ GroupKFold + é€æŠ˜ StandardScaler / GroupKFold by `game_id` + per-fold scaler |
| **é›†æˆ / Ensemble** | 5 æŠ˜æ¨¡å‹å¹³å‡ / 5-fold model averaging |

---

## ğŸ’¡ æ ¸å¿ƒåˆ›æ–°ï¼šå‡ ä½•ç»ˆç‚¹åŸºçº¿ / Core Innovation: Geometric Endpoint Baseline

### åŠ¨æœº / Motivation

**ä¸­æ–‡ï¼š**
åœ¨å¼€æ”¾åæ ‡ç©ºé—´ä¸Šçš„è½¨è¿¹é¢„æµ‹æœ¬è´¨ä¸Šå›°éš¾ã€‚å¦‚æœè®©ç¥ç»ç½‘ç»œç›´æ¥é¢„æµ‹ç»å¯¹ (x, y)ï¼Œå®ƒå¿…é¡»åŒæ—¶ä»æ•°æ®ä¸­å‘ç°ç‰©ç†è§„å¾‹ï¼ˆæƒ¯æ€§ï¼‰ã€æˆ˜æœ¯é€»è¾‘ï¼ˆè°å»å“ªé‡Œï¼‰å’Œäº¤äº’å½±å“ï¼ˆå¯¹æ‰‹å¦‚ä½•å½±å“è¿åŠ¨ï¼‰â€”â€”è¾“å‡ºç©ºé—´è¿‡å¤§ï¼Œæ”¶æ•›å›°éš¾ï¼Œå°¤å…¶æ˜¯è¿œæœŸå¸§ã€‚

**English:**
Trajectory prediction over an open coordinate space is fundamentally hard. Predicting absolute (x, y) requires the model to simultaneously discover physics (inertia), tactics (who goes where), and interactions (opponent influence) from data alone â€” leading to a vast output space and slow convergence, especially for far-future frames.

### æ–¹æ³•ï¼šè§„åˆ™å…ˆéªŒ + ç¥ç»ç½‘ç»œæ®‹å·® / Approach: Rule-Based Prior + Neural Residual

ä¸ºæ¯åçƒå‘˜ç”¨å¯è§£é‡Šè§„åˆ™æ„é€ **å‡ ä½•ç»ˆç‚¹**ï¼Œå†è®©æ¨¡å‹å­¦ä¹ **ä¿®æ­£é‡**ã€‚

Construct a **geometric endpoint** per player using interpretable rules, then let the model learn **corrections**.

```mermaid
flowchart LR
    subgraph Rules["è§„åˆ™ / Rules"]
        R1["ğŸƒ é»˜è®¤ Default\nposition + velocity Ã— t"]
        R2["ğŸ¯ ç›®æ ‡æ¥çƒæ‰‹ Receiver\nball landing point"]
        R3["ğŸ›¡ï¸ é˜²å®ˆè¦†ç›– Coverage\nlanding + mirror offset"]
        R4["ğŸ“ æ‰€æœ‰çƒå‘˜ All\nclip to field bounds"]
    end

    subgraph Derived["æ´¾ç”Ÿç‰¹å¾ / Derived Features"]
        D1["geo_vector æ–¹å‘å‘é‡"]
        D2["geo_distance è·ç¦»"]
        D3["required velocity / acceleration\næ‰€éœ€é€Ÿåº¦ / åŠ é€Ÿåº¦"]
        D4["velocity error & alignment\né€Ÿåº¦è¯¯å·® & å¯¹é½åº¦"]
    end

    Rules --> Derived
    Derived -->|"èå…¥ 167 ç»´ç‰¹å¾\nfeeds into 167-dim vector"| Model["GRU æ¨¡å‹\nlearns residual"]
```

### ä¸ºä»€ä¹ˆæœ‰æ•ˆ / Why It Works

| æ— å‡ ä½•å…ˆéªŒ / Without prior | æœ‰å‡ ä½•å…ˆéªŒ / With prior |
|---|---|
| æ¨¡å‹éœ€ä»æ•°æ®ä¸­å‘ç°æ¥çƒæ‰‹ä¼šè·‘å‘è½ç‚¹ / Model must discover receivers go to landing point | è§„åˆ™ç›´æ¥ç»™å‡ºç›®æ ‡ / Rule provides the target for free |
| è¾“å‡ºç©ºé—´ï¼šå…¨åœº (0-120, 0-53.3) / Output: full field | è¾“å‡ºç©ºé—´ï¼šåŸºçº¿é™„è¿‘çš„å°ä¿®æ­£ / Output: small corrections around baseline |
| è¿œæœŸå¸§éš¾æ”¶æ•› / Hard to converge for far future | æ›´å®¹æ˜“çš„ç›®æ ‡ â†’ æ›´å¿«æ”¶æ•› / Easier target â†’ faster convergence |

### å±€é™ / Limitation

é•œåƒæ¥çƒæ‰‹è§„åˆ™å‡è®¾äººç›¯äººé˜²å®ˆã€‚åœ¨åŒºåŸŸé˜²å®ˆä¸­ï¼Œæœ€è¿‘çš„æ¥çƒæ‰‹å¾€å¾€ä¸æ˜¯ç›¯é˜²ç›®æ ‡ï¼Œé•œåƒåç§»å˜æˆå™ªå£°ã€‚å·²é€šè¿‡è·ç¦»é˜ˆå€¼å’Œç½®ä¿¡åº¦ç‰¹å¾ç¼“è§£ï¼Œä½†æ›´å¥½çš„æ–¹æ¡ˆæ˜¯è®­ç»ƒé˜²å®ˆç­–ç•¥åˆ†ç±»å™¨ï¼ˆè§[åæ€](#-åæ€ä¸è¶³ä¸æœªæ¥æ–¹å‘--reflections-limitations--future-directions)ï¼‰ã€‚

The mirror-receiver rule assumes man-to-man coverage. In zone defense the nearest receiver is often not the assigned target, turning the mirror offset into noise. Mitigated with a distance threshold and confidence feature, but a proper coverage-scheme classifier would be the better long-term fix.

---

## ğŸ”§ æŠ€æœ¯æ¶æ„ / Technical Architecture

### ç«¯åˆ°ç«¯æµæ°´çº¿ / End-to-End Pipeline

```mermaid
flowchart TD
    A["ğŸ“‚ åŸå§‹è¿½è¸ªæ•°æ® Raw Tracking CSV\n18 weeks Ã— ~22 players Ã— ~10 frames/play"]

    A --> B

    subgraph B["ç‰¹å¾å·¥ç¨‹ Feature Engineering â€” data_fe.py"]
        direction TB
        B1["é€Ÿåº¦åˆ†è§£ Â· ç‰©ç†ç‰¹å¾\nVelocity Â· Physics"]
        B2["çƒå‡ ä½• Â· å¯¹æ‰‹äº¤äº’\nBall geometry Â· Opponent"]
        B3["é•œåƒæ¥çƒæ‰‹ Â· è·¯çº¿èšç±»\nMirror receiver Â· Route clustering"]
        B4["GNN-lite é‚»å±… Â· æ—¶é—´å¯¼æ•°\nNeighbors Â· Temporal"]
        B5["â˜… å‡ ä½•ç»ˆç‚¹ + æ´¾ç”Ÿç‰¹å¾\nGeometric endpoint + derived"]
        B1 ~~~ B2 ~~~ B3 ~~~ B4 ~~~ B5
    end

    B -->|"167 ç»´/å¸§\n167-dim/frame"| C

    subgraph C["åºåˆ—æ„é€  Sequence Construction"]
        C1["è¾“å…¥ Input: last 10 frames â†’ [10, 167]"]
        C2["ç›®æ ‡ Target: relative displacement"]
        C3["å¡«å…… Pad to H=94 with mask"]
        C1 ~~~ C2 ~~~ C3
    end

    C --> D

    subgraph D["æ¨¡å‹ Model â€” JointSeqModel"]
        D1["GRU (2 layers, hidden=128)"]
        D2["Attention Pooling\nå¯å­¦ä¹ æŸ¥è¯¢, 4 heads"]
        D3["MLP (128â†’256â†’GELUâ†’94Ã—2)"]
        D4["cumsum â†’ ç´¯ç§¯ä½ç§»\ncumulative displacement"]
        D1 --> D2 --> D3 --> D4
    end

    D --> E

    subgraph E["åå¤„ç† Post-Processing â€” inference.py"]
        E1["ç»å¯¹åæ ‡ = æœ«å¸§ä½ç½® + ä½ç§»\nabsolute_pos = last_pos + disp"]
        E2["åœºåœ°è¾¹ç•Œè£å‰ª Field clipping"]
        E3["5 æŠ˜é›†æˆå¹³å‡ Ensemble average"]
        E1 ~~~ E2 ~~~ E3
    end

    E --> F["ğŸ“„ submission.csv"]
```

### ç‰¹å¾åˆ†ç»„ / Feature Groups (167 ç»´ / dimensions)

```mermaid
mindmap
  root(("167 ç»´ç‰¹å¾\n167-dim Features"))
    ç‰©ç†/è¿åŠ¨å­¦ Physics ~20
      velocity_x/y é€Ÿåº¦
      momentum åŠ¨é‡
      kinetic_energy åŠ¨èƒ½
    çƒå‡ ä½• Ball Geometry ~12
      distance_to_ball è·ç¦»
      closing_speed æ¥è¿‘é€Ÿåº¦
      velocity_alignment å¯¹é½åº¦
    å¯¹æ‰‹äº¤äº’ Opponent ~15
      nearest_opp_dist æœ€è¿‘å¯¹æ‰‹
      mirror_wr é•œåƒæ¥çƒæ‰‹
      pressure å‹åŠ›
    è·¯çº¿/é‚»åŸŸ Route & Neighbor ~25
      route_pattern è·¯çº¿æ¨¡å¼ K=7
      GNN-lite embeddings é‚»å±…åµŒå…¥
    æ—¶é—´å¯¼æ•° Temporal ~60
      lag 1-5 æ»å
      rolling mean/std æ»šåŠ¨
      delta, EMA å˜åŒ–ç‡
    â˜… å‡ ä½•ç»ˆç‚¹ Geo Endpoint ~15
      geo_endpoint_x/y ç»ˆç‚¹
      geo_vector æ–¹å‘
      geo_velocity_error é€Ÿåº¦è¯¯å·®
    èº«ä»½ Identity ~10
      is_receiver æ¥çƒæ‰‹
      is_coverage è¦†ç›–
      is_passer ä¼ çƒæ‰‹
    æ—¶é—´/è¿›åº¦ Time ~10
      time_remaining å‰©ä½™æ—¶é—´
      progress_ratio è¿›åº¦
```

### æ¨¡å‹æ¶æ„ç»†èŠ‚ / Model Architecture Detail

```mermaid
flowchart TD
    Input["è¾“å…¥ Input\n[B, T=10, F=167]"]

    Input --> GRU["GRU\n2 layers, hidden=128\ndropout=0.1"]
    GRU -->|"[B, 10, 128]"| LN["LayerNorm"]

    Q["å¯å­¦ä¹ æŸ¥è¯¢ Learnable Query\n[1, 128] â†’ expand [B, 1, 128]"]
    LN --> Attn["å¤šå¤´æ³¨æ„åŠ› MultiHead Attention\n4 heads"]
    Q --> Attn

    Attn -->|"[B, 1, 128] â†’ squeeze"| MLP

    subgraph MLP["MLP Head"]
        L1["Linear 128â†’256"] --> GELU["GELU"] --> L2["Linear 256â†’94Ã—2"]
    end

    MLP -->|"[B, 94, 2]\né€æ­¥å¢é‡ per-step deltas"| CUM["cumsum(dim=1)"]
    CUM -->|"[B, 94, 2]\nç´¯ç§¯ä½ç§» cumulative disp"| OUT["è¾“å‡º Output"]
```

### æ¶æ„å†³ç­– / Architecture Decisions

| å†³ç­– / Decision | ç†ç”± / Rationale |
|---|---|
| GRU è€Œé Transformer / GRU over Transformer | è¾“å…¥åºåˆ—çŸ­ (T=10)ï¼ŒGRU å‚æ•°å°‘ã€æ”¶æ•›å¿« / Short input; fewer params, faster convergence |
| æ³¨æ„åŠ›æ± åŒ– è€Œé æœ€åéšçŠ¶æ€ / Attention Pooling over last hidden | å­¦ä¹ å…³æ³¨ä¿¡æ¯é‡æœ€å¤§çš„å¸§ï¼ˆé€šå¸¸ä¸ºå‡ºæ‰‹å‰ 2â€“3 å¸§ï¼‰/ Learns to focus on most informative frames |
| å¢é‡è¾“å‡º + cumsum / Delta + cumsum | å°†å¤æ‚è½¨è¿¹åˆ†è§£ä¸ºå¯å­¦ä¹ çš„å°æ­¥ / Decomposes trajectory into learnable small steps |
| å•æ¬¡ MLPï¼ˆéè‡ªå›å½’ï¼‰/ Single-pass MLP | é¿å…é•¿æ—¶é¢„æµ‹ä¸­çš„è¯¯å·®ç´¯ç§¯ï¼›æ¨ç†æ›´å¿« / Avoids error accumulation; faster inference |

### è®­ç»ƒé…ç½® / Training Configuration

| é¡¹ç›® / Item | è®¾ç½® / Setting |
|---|---|
| äº¤å‰éªŒè¯ / CV | GroupKFold (5 folds, groups=`game_id`) |
| æ ‡å‡†åŒ– / Scaler | é€æŠ˜ StandardScalerï¼ˆä»…åœ¨è®­ç»ƒé›† fitï¼‰/ Per-fold, fit on train only |
| ä¼˜åŒ–å™¨ / Optimizer | AdamW (lr=1e-3, weight_decay=1e-5) |
| è°ƒåº¦å™¨ / Scheduler | ReduceLROnPlateau (patience=5, factor=0.5) |
| æ¢¯åº¦è£å‰ª / Grad clip | `clip_grad_norm = 1.0` |
| æ—©åœ / Early stopping | patience=30, æ¢å¤æœ€ä½³æƒé‡ / restore best weights |
| æŸå¤± / Loss | Temporal Huber (Î´=0.5, time-decay Î»=0.03) |

---

## ğŸ›  å…³é”®å·¥ç¨‹æŒ‘æˆ˜ä¸è§£å†³ / Key Engineering Challenges & Solutions

### 1. NaN ä¼ æ’­ / NaN Propagation

**ç°è±¡ / Symptomï¼š** è®­ç»ƒæŸå¤±åœ¨ 2â€“3 ä¸ª epoch å†…çˆ†ç‚¸ä¸º NaNã€‚
Training loss exploded to NaN within 2â€“3 epochs.

**æ ¹å›  / Root Causeï¼š** Lag/rolling ç‰¹å¾å¯¹æ—©æœŸå¸§äº§ç”Ÿ NaN â†’ æ±¡æŸ“ StandardScaler çš„ `fit()` â†’ ç¼©æ”¾åå‡ºç° Â±âˆ â†’ GRU æº¢å‡ºã€‚
Lag/rolling features produce NaN for early frames â†’ corrupt scaler mean/std â†’ Â±âˆ after scaling â†’ GRU overflow.

**è§£å†³ / Fixï¼š** ç¼©æ”¾å‰ç”¨é€ç©å®¶å‡å€¼å¡«å……ï¼›ä¸¢å¼ƒä»å« NaN çš„åºåˆ—ï¼›æ¢¯åº¦è£å‰ªå…œåº•ã€‚
Fill NaN with per-player means before scaling; discard remaining NaN sequences; gradient clipping as safety net.

**ç»éªŒ / Lessonï¼š** ç‰¹å¾æ­£ç¡®æ€§å¿…é¡»åœ¨æ¨¡å‹è¾“å…¥è¾¹ç•Œå¤„éªŒè¯ï¼Œè€Œéå­¤ç«‹æ£€æŸ¥ã€‚
Validate features at the model input boundary, not in isolation.

---

### 2. æ•°æ®æ³„æ¼ / Data Leakage

**ç°è±¡ / Symptomï¼š** éªŒè¯æŸå¤±å¼‚å¸¸åœ°æ¯”è®­ç»ƒæŸå¤±ä½ 15â€“20%ã€‚
Val loss suspiciously 15â€“20% lower than train loss.

**æ ¹å›  / Root Causeï¼š** æ ‡å‡† KFold å¯¼è‡´åŒåœºæ¯”èµ›çš„ä¸åŒ play æ³„æ¼åˆ°è®­ç»ƒ/éªŒè¯ä¸¤ç«¯ã€‚
Standard KFold let plays from the same game leak across train/val splits.

**è§£å†³ / Fixï¼š** æ”¹ç”¨ `GroupKFold(groups=game_id)`ã€‚
Switched to `GroupKFold(groups=game_id)`.

**ç»éªŒ / Lessonï¼š** å¼‚å¸¸å¥½çš„éªŒè¯æŒ‡æ ‡æ˜¯æ³„æ¼çš„å¼ºä¿¡å·ï¼›ä½“è‚²æ•°æ®å¿…é¡»æŒ‰æ¯”èµ›çº§åˆ«åˆ’åˆ†ã€‚
Abnormally good val metrics signal leakage; sports data requires game-level splits.

---

### 3. é¢†åŸŸå¯å‘å¼ç¼ºå°‘ç½®ä¿¡åº¦ / Domain Heuristic Without Confidence

**ç°è±¡ / Symptomï¼š** æ·»åŠ é•œåƒæ¥çƒæ‰‹ç‰¹å¾åï¼Œé˜²å®ˆè€… RMSE åè€Œæ¶åŒ–ã€‚
Adding mirror-receiver features worsened defensive player RMSE.

**æ ¹å›  / Root Causeï¼š** åŒºåŸŸé˜²å®ˆä¸­ï¼Œæœ€è¿‘æ¥çƒæ‰‹ â‰  ç›¯é˜²ç›®æ ‡ï¼Œé•œåƒåç§»æˆä¸ºå™ªå£°ã€‚
In zone defense, nearest receiver â‰  assigned target; mirror offset becomes noise.

**è§£å†³ / Fixï¼š** è·ç¦»é˜ˆå€¼ (`mirror_dist < 15`) + è€¦åˆç½®ä¿¡åº¦ç‰¹å¾ã€‚
Distance threshold + coupling-confidence feature.

**ç»éªŒ / Lessonï¼š** é¢†åŸŸå…ˆéªŒå¿…é¡»é™„å¸¦ç½®ä¿¡åº¦é—¨æ§ã€‚
Domain priors must come with confidence gates.

---

### 4. å†…å­˜ä¸è¿è¡Œæ—¶é—´ / Memory & Runtime

**ç°è±¡ / Symptomï¼š** GNN-lite è‡ªè¿æ¥äº§ç”Ÿ 280 ä¸‡è¡Œ DataFrameï¼ˆOOMï¼‰ï¼›å¯¹æ‰‹ç‰¹å¾è€—æ—¶ 40+ åˆ†é’Ÿã€‚
GNN-lite self-join â†’ 2.8M rows (OOM); opponent features took 40+ minutes.

**è§£å†³ / Fixï¼š** è¿æ¥å‰ä»… 6 åˆ— â†’ æŒ‰åŠå¾„è¿‡æ»¤ â†’ k=6 é‚»å±…ï¼›å¯¹æ‰‹ç‰¹å¾ä»…æœ€åä¸€å¸§ + NumPy å‘é‡åŒ–ã€‚
6 columns before join â†’ radius filter â†’ k=6 cap; opponent features on last frame only + vectorized NumPy.

**ç»éªŒ / Lessonï¼š** O(NÂ²) æ“ä½œéœ€æ¿€è¿›çš„æ—©æœŸè¿‡æ»¤å’Œåˆ—å‰ªæã€‚
O(NÂ²) operations demand aggressive early filtering and column pruning.

---

### 5. è¾“å‡ºè¡¨ç¤ºï¼ˆå½±å“æœ€å¤§ï¼‰/ Output Representation (Most Impactful)

**ç°è±¡ / Symptomï¼š** é¢„æµ‹ç»å¯¹åæ ‡æ—¶ï¼Œå‰ 10 å¸§å°šå¯ï¼Œè¶… 30 å¸§åè¯¯å·®ç¾éš¾æ€§å¢é•¿ã€‚
Absolute (x, y) prediction: acceptable for first 10 frames, catastrophic beyond 30.

**è§£å†³ / Fixï¼š** æ”¹ä¸ºç›¸å¯¹ä½ç§» + é€æ­¥å¢é‡ + `cumsum` + æ—¶é—´è¡°å‡æƒé‡ â†’ RMSE æ”¹å–„ ~20â€“30%ã€‚
Switched to relative displacement + delta output + `cumsum` + time-decay weighting â†’ ~20â€“30% RMSE gain.

**ç»éªŒ / Lessonï¼š** è¾“å‡ºè¡¨ç¤ºé€‰æ‹©å¯¹æ€§èƒ½çš„å½±å“å¯ä»¥è¿œå¤§äºæ¨¡å‹æ¶æ„é€‰æ‹©ã€‚
Output representation choice can matter far more than model architecture choice.

---

## ğŸ“ˆ ç»“æœä¸æ¶ˆèå®éªŒ / Results & Ablation

### ç´¯ç§¯æ¶ˆè / Cumulative Ablation

| # | æ–°å¢ç»„ä»¶ / Component Added | å½±å“ / Impact |
|---|---|---|
| 0 | åŒ€é€Ÿå¤–æ¨ï¼ˆæ—  MLï¼‰/ Constant-velocity extrapolation | åŸºçº¿ Baseline |
| 1 | GRU + åŸºç¡€è¿½è¸ªç‰¹å¾ / GRU + basic tracking | æ˜¾è‘— â†“ Significant â†“ |
| 2 | çƒå‡ ä½•ç‰¹å¾ / Ball geometry features | å¤§å¹… â†“ Large â†“ |
| 3 | å¯¹æ‰‹äº¤äº’ + é•œåƒæ¥çƒæ‰‹ / Opponent + mirror receiver | æ˜æ˜¾ â†“ Notable â†“ |
| 4 | è·¯çº¿èšç±» + GNN-lite / Route clustering + GNN-lite | ä¸­ç­‰ â†“ Moderate â†“ |
| 5 | æ—¶é—´å¯¼æ•° / Temporal derivatives | ä¸­ç­‰ â†“ Moderate â†“ |
| **6** | **â˜… å‡ ä½•ç»ˆç‚¹åŸºçº¿ / Geometric Endpoint Baseline** | **æœ€å¤§å•ä¸€ â†“ Largest single â†“** |
| 7 | å¢é‡è¾“å‡º + cumsum / Delta output + cumsum | å¤§å¹… â†“ Large â†“ |
| 8 | Temporal Huber + 5 æŠ˜é›†æˆ / + 5-fold ensemble | å°å¹… â†“ + æ–¹å·®ç¼©å‡ |

> **æ³¨ / Noteï¼š** ä¸ºé¿å…å¯¹ private leaderboard è¿‡æ‹Ÿåˆï¼Œæ­¤å¤„çœç•¥å…·ä½“ RMSE å€¼ã€‚ä»¥ä¸Šæ’åºåœ¨ 5 ä¸ª CV æŠ˜ä¸­ä¸€è‡´ã€‚
> Exact RMSE values omitted. Relative ordering was consistent across all 5 CV folds.

### å„è§’è‰²é¢„æµ‹éš¾åº¦ / Difficulty by Player Role

| è§’è‰² / Role | éš¾åº¦ / Difficulty | åŸå›  / Reasoning |
|---|---|---|
| ä¼ çƒæ‰‹ QB / Passer | ä½ Low | å‡ºæ‰‹ååŸºæœ¬é™æ­¢ / Mostly stationary after release |
| ç›®æ ‡æ¥çƒæ‰‹ / Targeted Receiver | ä¸­ Medium | æœ‰å¼ºè½ç‚¹å…ˆéªŒï¼Œä½†å¼§çº¿/å‡é€Ÿéš¾é¢„æµ‹ / Strong prior, but curvature hard |
| é˜²å®ˆè¦†ç›– / Defensive Coverage | é«˜ High | äººç›¯äºº/åŒºåŸŸæ¨¡ç³Šï¼›é•œåƒè´¨é‡ä¸ç¨³å®š / Man-vs-zone ambiguity |
| å…¶ä»–è·¯çº¿è·‘æ‰‹ / Other Route Runners | é«˜ High | æ— ç›´æ¥è½ç‚¹çº¦æŸï¼›è·¯çº¿å¤šæ · / No landing constraint; diverse routes |
| æ‹¦æˆªè€…ç­‰ / Blockers / Others | ä¸­ Medium | æƒ¯æ€§å¤–æ¨å°šå¯ï¼›å¯¹æŠ—æ¥è§¦è¾ƒéš¾ / Inertia works; contact harder |

---

## ğŸ“ ä»“åº“ç»“æ„ä¸èµ›é¢˜å¯¹é½ / Repository Structure & Competition Alignment

### ä»“åº“æ–‡ä»¶ / Repository Files

```
NFL-Big-Data-Bowl-2026/
â”‚
â”œâ”€â”€ README.md                      â† æœ¬æ–‡ä»¶ï¼ˆä¸­è‹±å¯¹ç…§ï¼‰/ This file (bilingual)
â”œâ”€â”€ LICENSE
â”œâ”€â”€ requirements.txt               â† ç²¾ç¡®ä¾èµ–ç‰ˆæœ¬ / Pinned dependencies
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_eda.ipynb               â† æ•°æ®æ¢ç´¢ä¸å¯è§†åŒ– / EDA & visualization
â”‚   â”œâ”€â”€ 02_feature_analysis.ipynb  â† SHAP / ç‰¹å¾é‡è¦æ€§ / Feature importance
â”‚   â””â”€â”€ 03_error_analysis.ipynb    â† åˆ†è§’è‰²è¯¯å·®åˆ†æ / Error breakdown by role
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ utils.py                   â† éšæœºç§å­ / Seed & reproducibility
â”‚   â”œâ”€â”€ data_fe.py                 â† ç‰¹å¾å·¥ç¨‹ (167 features) / Feature engineering
â”‚   â”œâ”€â”€ models.py                  â† JointSeqModel + TemporalHuber
â”‚   â”œâ”€â”€ train.py                   â† GroupKFold è®­ç»ƒå¾ªç¯ / Training loop
â”‚   â””â”€â”€ inference.py               â† 5 æŠ˜é›†æˆæ¨ç† / 5-fold ensemble inference
â”‚
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ default.yaml               â† è¶…å‚æ•°é…ç½® / Hyperparameters
â”‚
â”œâ”€â”€ outputs/                       â† è®­ç»ƒç”Ÿæˆ (gitignored) / Generated at training
â”‚   â”œâ”€â”€ exp_models_scalers.pkl     â† 5 æŠ˜æ¨¡å‹ + scaler / 5-fold models + scalers
â”‚   â”œâ”€â”€ route_kmeans_scaler.pkl    â† è·¯çº¿èšç±»å™¨ / Route clustering artifacts
â”‚   â””â”€â”€ submission.csv             â† æœ€ç»ˆæäº¤æ–‡ä»¶ / Final submission
â”‚
â””â”€â”€ input/                         â† æ¯”èµ›æ•°æ® (gitignored) / Competition data
    â””â”€â”€ nfl-big-data-bowl-2026-prediction/
        â”œâ”€â”€ train/
        â”‚   â”œâ”€â”€ input_2023_w01.csv ... input_2023_w18.csv
        â”‚   â””â”€â”€ output_2023_w01.csv ... output_2023_w18.csv
        â”œâ”€â”€ test_input.csv
        â”œâ”€â”€ test.csv
        â””â”€â”€ sample_submission.csv
```

> æ‰€æœ‰æ¶æ„å›¾ä»¥ Mermaid åµŒå…¥ï¼ŒGitHub åŸç”Ÿæ¸²æŸ“ï¼Œæ— éœ€é¢å¤–å›¾ç‰‡ã€‚
> All diagrams are Mermaid-embedded; GitHub renders them natively.

### ä»“åº“ä¸æ¯”èµ›è¦æ±‚çš„å¯¹é½ / How This Repo Maps to Competition Requirements

ä¸‹è¡¨å±•ç¤ºä»“åº“ç»“æ„å¦‚ä½•å¯¹åº” Kaggle æ¯”èµ›çš„æ•°æ®æ ¼å¼å’Œæäº¤è§„èŒƒï¼Œå®¡é˜…è€…å¯å¯¹ç…§éªŒè¯ã€‚

The following table shows how the repository maps to the competition's data format and submission requirements. Reviewers can cross-reference with the [official data page](https://www.kaggle.com/competitions/nfl-big-data-bowl-2026-prediction/data).

| æ¯”èµ›è¦æ±‚ / Competition Requirement | ä»“åº“å¯¹åº” / Repo Implementation | è¯´æ˜ / Notes |
|---|---|---|
| **è®­ç»ƒæ•°æ® / Training Data** â€” `train/input_*.csv` (å‡ºæ‰‹å‰è¿½è¸ª) + `train/output_*.csv` (å‡ºæ‰‹åçœŸå®åæ ‡) | `input/nfl-big-data-bowl-2026-prediction/train/` | 18 å‘¨ Ã— è¾“å…¥/è¾“å‡ºé…å¯¹ / 18 weeks Ã— input/output pairs |
| **æµ‹è¯•æ•°æ® / Test Data** â€” `test_input.csv` (å‡ºæ‰‹å‰è¿½è¸ª) + `test.csv` (æ¯è¡Œéœ€é¢„æµ‹çš„ play-player-frame ç´¢å¼•) | `input/.../test_input.csv` + `input/.../test.csv` | 2025 èµ›å­£ Weeks 14â€“18 çš„å®æ—¶æ•°æ® / Live 2025 season data |
| **æäº¤æ ¼å¼ / Submission Format** â€” CSV å« `uniqueId`, `player_x`, `player_y` åˆ—ï¼Œä¸ `sample_submission.csv` æ ¼å¼ä¸€è‡´ | `outputs/submission.csv` ç”± `inference.py` ç”Ÿæˆ | é€è¡Œå¯¹åº” `test.csv` ä¸­çš„ play-player-frame ç»„åˆ / Row-aligned with test.csv |
| **è¯„ä¼°æŒ‡æ ‡ / Metric** â€” æ‰€æœ‰é¢„æµ‹åæ ‡çš„ RMSE | `models.py` ä¸­ TemporalHuber ä¸ºè®­ç»ƒæŸå¤±ï¼›æœ¬åœ° CV ç”¨ RMSE è¯„ä¼° | è®­ç»ƒæŸå¤± â‰  è¯„ä¼°æŒ‡æ ‡ï¼ˆHuber vs RMSEï¼‰ï¼Œä½†æ–¹å‘ä¸€è‡´ / Train loss â‰  eval metric, but directionally aligned |
| **Kaggle Notebook ç¯å¢ƒ / Notebook Environment** â€” P100 GPU, 16 GB RAM, 9 å°æ—¶æ—¶é™ | ä»£ç å·²åœ¨ Kaggle Notebook ç¯å¢ƒéªŒè¯é€šè¿‡ | è®­ç»ƒ + æ¨ç†æ€»è€—æ—¶ < 9 å°æ—¶ / Total runtime < 9h limit |
| **ä¸å¯ä½¿ç”¨å¤–éƒ¨æ•°æ® / No External Data** | ä»…ä½¿ç”¨æ¯”èµ›æä¾›çš„ tracking CSV | æœªä½¿ç”¨ä»»ä½•é¢å¤–æ•°æ®æº / No supplementary data used |
| **æäº¤åå®æ—¶è¯„ä¼° / Live Evaluation** | æäº¤åç”± Kaggle å¯¹ 2025 èµ›å­£çœŸå®æ•°æ®è¯„åˆ†ï¼Œç»“æœæ˜¾ç¤ºåœ¨ [public leaderboard](https://www.kaggle.com/competitions/nfl-big-data-bowl-2026-prediction/leaderboard) | éç¦»çº¿è¯„ä¼°ï¼Œç¡®ä¿æ— æ³•ä½œå¼Š / Live scoring prevents cheating |

### å…³é”®é¢„å¤„ç†åˆ¶å“ä¸å¯å¤ç°æ€§ / Preprocessing Artifacts & Reproducibility

| åˆ¶å“ / Artifact | ç”Ÿæˆæ—¶æœº / Created At | æ¨ç†æ—¶ç”¨é€” / Used At Inference | ä¸ºä»€ä¹ˆé‡è¦ / Why It Matters |
|---|---|---|---|
| `exp_models_scalers.pkl` | `train.py` è®­ç»ƒç»“æŸ | `inference.py` åŠ è½½æ¨¡å‹æƒé‡ + scaler | åŒ…å« 5 ä¸ª GRU æ¨¡å‹ + 5 ä¸ª StandardScaler |
| `route_kmeans_scaler.pkl` | `train.py` é¦–æ¬¡è°ƒç”¨ `extract_route_patterns(fit=True)` | `inference.py` è°ƒç”¨ `extract_route_patterns(fit=False)` | ç¡®ä¿è®­ç»ƒ/æ¨ç†ä½¿ç”¨åŒä¸€èšç±»ä¸­å¿ƒï¼Œé˜²æ­¢æ ‡ç­¾è¯­ä¹‰æ¼‚ç§» / Prevents label semantic drift |
| `configs/default.yaml` | æ‰‹åŠ¨ç¼–å†™ | è®­ç»ƒå’Œæ¨ç†å‡è¯»å– | æ‰€æœ‰è¶…å‚æ•°é›†ä¸­ç®¡ç†ï¼Œç¡®ä¿å®éªŒå¯è¿½æº¯ / Single source of truth for all hyperparameters |

---

## ğŸš€ å¤ç°æŒ‡å— / Reproduction Guide

### ç¯å¢ƒè¦æ±‚ / Environment Requirements

| é¡¹ç›® / Item | è¦æ±‚ / Requirement |
|---|---|
| **Python** | 3.10.x |
| **CUDA** | 11.8+ (å¦‚ä½¿ç”¨ GPU / if using GPU) |
| **GPU** | NVIDIA P100 / RTX 3090 æˆ–åŒç­‰ / or equivalentï¼ˆCPU å¯è¿è¡Œä½†è®­ç»ƒæ…¢ ~10x / CPU works but ~10x slowerï¼‰ |
| **RAM** | â‰¥ 16 GB |
| **ç£ç›˜ / Disk** | â‰¥ 5 GBï¼ˆæ•°æ® + æ¨¡å‹æƒé‡ / data + model weightsï¼‰ |

### æ ¸å¿ƒä¾èµ– / Key Dependencies

```
torch>=2.0.0,<2.2.0
pandas>=1.5.0
numpy>=1.23.0
scikit-learn>=1.2.0
tqdm>=4.65.0
pyyaml>=6.0
```

å®Œæ•´åˆ—è¡¨è§ `requirements.txt`ï¼ˆå·²é”å®šç‰ˆæœ¬å·ï¼‰ã€‚
Full pinned list in `requirements.txt`.

### æ“ä½œæ­¥éª¤ / Step-by-Step

```bash
# 0. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼ˆæ¨èï¼‰/ Create virtual environment (recommended)
conda create -n bdb2026 python=3.10 -y
conda activate bdb2026

# 1. å®‰è£…ä¾èµ– / Install dependencies
pip install -r requirements.txt

# 2. ä¸‹è½½æ¯”èµ›æ•°æ®ï¼ˆéœ€è¦ Kaggle è´¦å· + åŒæ„æ¯”èµ›è§„åˆ™ï¼‰
#    Download data (requires Kaggle account + accepting competition rules)
#    æ¯”èµ›æ•°æ®é¡µ: https://www.kaggle.com/competitions/nfl-big-data-bowl-2026-prediction/data
pip install kaggle
kaggle competitions download -c nfl-big-data-bowl-2026-prediction
mkdir -p input && unzip nfl-big-data-bowl-2026-prediction.zip -d input/nfl-big-data-bowl-2026-prediction/

# 3. éªŒè¯æ•°æ®å®Œæ•´æ€§ / Verify data integrity
ls input/nfl-big-data-bowl-2026-prediction/train/
#    åº”çœ‹åˆ° / Should see:
#    input_2023_w01.csv ... input_2023_w18.csv
#    output_2023_w01.csv ... output_2023_w18.csv

ls input/nfl-big-data-bowl-2026-prediction/
#    åº”çœ‹åˆ° / Should see:
#    test_input.csv  test.csv  sample_submission.csv

# 4. è®­ç»ƒ / Train
#    é¢„è®¡è€—æ—¶: RTX 3090 çº¦ 2â€“3 å°æ—¶, P100 çº¦ 3â€“4 å°æ—¶
#    Expected time: ~2â€“3h on RTX 3090, ~3â€“4h on P100
cd src && python train.py
#    è¾“å‡º / Outputs:
#      ../outputs/exp_models_scalers.pkl    (5-fold models + scalers, ~500 MB)
#      ../outputs/route_kmeans_scaler.pkl   (route clustering, ~1 MB)

# 5. æ¨ç† / Inference
#    é¢„è®¡è€—æ—¶: çº¦ 10 åˆ†é’Ÿ / Expected time: ~10 min
python inference.py
#    è¾“å‡º / Output:
#      ../outputs/submission.csv

# 6. éªŒè¯æäº¤æ ¼å¼ / Verify submission format
python -c "
import pandas as pd
sub = pd.read_csv('../outputs/submission.csv')
sample = pd.read_csv('../input/nfl-big-data-bowl-2026-prediction/sample_submission.csv')
assert list(sub.columns) == list(sample.columns), 'Column mismatch!'
assert len(sub) == len(sample), f'Row count mismatch: {len(sub)} vs {len(sample)}'
assert sub['player_x'].between(0, 120).all(), 'x out of bounds!'
assert sub['player_y'].between(0, 53.3).all(), 'y out of bounds!'
print(f'âœ… Submission valid: {len(sub)} rows, columns={list(sub.columns)}')
"
```

### åœ¨ Kaggle Notebook ä¸­è¿è¡Œ / Running on Kaggle Notebooks

æœ¬æ–¹æ¡ˆå·²åœ¨ Kaggle Notebook ç¯å¢ƒ (P100, 16 GB RAM, 9h é™åˆ¶) ä¸‹éªŒè¯ã€‚å¦‚éœ€åœ¨ Kaggle ä¸Šç›´æ¥è¿è¡Œï¼š

This solution has been verified on Kaggle Notebooks (P100, 16 GB RAM, 9h limit). To run directly on Kaggle:

1. æ–°å»º Notebookï¼Œæ·»åŠ æ¯”èµ›æ•°æ®é›† / Create Notebook, add competition dataset
2. å¼€å¯ GPU åŠ é€Ÿå™¨ / Enable GPU accelerator
3. å°† `src/` ä¸‹æ–‡ä»¶ä¸Šä¼ æˆ–ç²˜è´´åˆ° Notebook cells
4. ä¿®æ”¹æ•°æ®è·¯å¾„ä¸º `/kaggle/input/nfl-big-data-bowl-2026-prediction/`
5. ä¾æ¬¡è¿è¡Œ train â†’ inference cells
6. æäº¤ `submission.csv` åˆ° [æ¯”èµ›æäº¤é¡µ](https://www.kaggle.com/competitions/nfl-big-data-bowl-2026-prediction/submissions)

---

## ğŸ“ åæ€ã€ä¸è¶³ä¸æœªæ¥æ–¹å‘ / Reflections, Limitations & Future Directions

### æ–¹æ³•è®ºåæ€ / Methodological Reflections

**1. å…ˆéªŒæ³¨å…¥ vs. æ¨¡å‹å¤æ‚åº¦ / Prior injection vs. model complexity**

å‡ è¡Œè§„åˆ™ä»£ç ï¼ˆå‡ ä½•ç»ˆç‚¹åŸºçº¿ï¼‰çš„è´¡çŒ®è¶…è¿‡äº†æ‰€æœ‰æ¨¡å‹æ¶æ„è°ƒæ•´çš„æ€»å’Œã€‚å¥½çš„å½’çº³åç½®èƒ½å¤§å¹…ç¼©å°æ¨¡å‹éœ€è¦ä»æ•°æ®ä¸­å­¦ä¹ çš„èŒƒå›´ï¼Œè¿™ä¸ physics-informed neural networks çš„ç ”ç©¶æ–¹å‘ä¸€è‡´ã€‚

A few lines of rule-based code (geometric endpoint) contributed more than all architecture changes combined. Good inductive bias dramatically reduces what the model must learn from data â€” consistent with the physics-informed neural network paradigm.

**2. è¾“å‡ºè¡¨ç¤ºæ˜¯è¢«ä½ä¼°çš„è®¾è®¡ç»´åº¦ / Output representation is an underappreciated design axis**

ç»å¯¹åæ ‡ â†’ ç›¸å¯¹ä½ç§»å¸¦æ¥ 20â€“30% RMSE æ”¹å–„ã€‚å»ºæ¨¡æ—¶ä¸åº”åªå…³æ³¨æ¨¡å‹å†…éƒ¨ï¼ˆå±‚æ•°ã€æ³¨æ„åŠ›å¤´æ•°ï¼‰ï¼Œè¿˜åº”ä»”ç»†æ€è€ƒè¾“å…¥è¾“å‡ºçš„è¡¨ç¤ºæ–¹å¼â€”â€”è¡¨ç¤ºé€‰æ‹©æœ¬è´¨ä¸Šæ”¹å˜äº†ä¼˜åŒ– landscape çš„å½¢çŠ¶ã€‚

Absolute â†’ relative displacement yielded ~20â€“30% RMSE gain. When modeling, one should not focus solely on model internals but carefully consider input/output representations â€” representation choice fundamentally reshapes the optimization landscape.

**3. é¢†åŸŸçŸ¥è¯†çš„åŒåˆƒæ€§ / The double-edged nature of domain knowledge**

é•œåƒæ¥çƒæ‰‹åœ¨äººç›¯äººä¸­æœ‰æ•ˆï¼Œåœ¨åŒºåŸŸé˜²å®ˆä¸­æœ‰å®³ã€‚è·ç¦»é˜ˆå€¼ + ç½®ä¿¡åº¦æ˜¯å·¥ç¨‹æŠ˜ä¸­ï¼›æ›´ç†æƒ³çš„åšæ³•æ˜¯è®­ç»ƒé˜²å®ˆç­–ç•¥åˆ†ç±»å™¨ã€‚æ™®éè§„å¾‹ï¼š**é¢†åŸŸå¯å‘å¼çš„ä»·å€¼å–å†³äºå…¶é€‚ç”¨æ¡ä»¶çš„æ¸…æ™°åº¦ã€‚**

Mirror receiver worked for man coverage but hurt in zone. General principle: **the value of a domain heuristic depends on the clarity of its applicability conditions.**

### æ˜ç¡®ä¸è¶³ / Known Limitations

| ä¸è¶³ / Limitation | è¯´æ˜ / Description |
|---|---|
| **ç‹¬ç«‹é¢„æµ‹** / Independent prediction | é€ç©å®¶ç‹¬ç«‹é¢„æµ‹ï¼Œå¿½ç•¥åè°ƒè¿åŠ¨ï¼ˆæ©æŠ¤ã€è½®è½¬ï¼‰/ Ignores coordinated movements (picks, zone rotations) |
| **ç‚¹ä¼°è®¡** / Point estimate only | æ— æ³•è¡¨è¾¾è¿œæœŸå¸§çš„å›ºæœ‰ä¸ç¡®å®šæ€§ / Cannot express inherent uncertainty in far-future frames |
| **æœªå½’ä¸€åŒ–æ–¹å‘** / No direction normalization | æœªç»Ÿä¸€è¿›æ”»æ–¹å‘ï¼Œæµªè´¹æ•°æ®å¯¹ç§°æ€§ / Wastes data symmetry from play direction |
| **é˜²å®ˆç­–ç•¥æœªå»ºæ¨¡** / Defense scheme not modeled | é•œåƒä¾èµ–è·ç¦»å¯å‘å¼ï¼ŒæœªåŒºåˆ†äººç›¯äºº/åŒºåŸŸ / Mirror uses distance heuristic, no man/zone distinction |

### ä¸‹ä¸€æ­¥æ–¹å‘ / Future Directions

1. **è”åˆå¤šæ™ºèƒ½ä½“å»ºæ¨¡ / Joint multi-agent modeling** â€” Graph Transformer æˆ– cross-player attention å»ºæ¨¡ 22 äººäº¤äº’
2. **æ¦‚ç‡è¾“å‡º / Probabilistic output** â€” Mixture Density Network æˆ–åˆ†ä½æ•°å›å½’æ•è·é¢„æµ‹ä¸ç¡®å®šæ€§
3. **åæ ‡ç³»å½’ä¸€åŒ– / Direction normalization** â€” ç»Ÿä¸€è¿›æ”»æ–¹å‘ï¼ˆå§‹ç»ˆå·¦â†’å³ï¼‰ï¼Œç­‰ä»·äºè®­ç»ƒæ•°æ®ç¿»å€
4. **é˜²å®ˆç­–ç•¥é—¨æ§ / Defense scheme gating** â€” å…ˆåˆ†ç±» man/zoneï¼Œå†å†³å®šæ˜¯å¦å¯ç”¨é•œåƒå…ˆéªŒ

---

## ğŸ›  æŠ€æœ¯æ ˆ / Tech Stack

| ç±»åˆ« / Category | å·¥å…· / Tools |
|---|---|
| æ·±åº¦å­¦ä¹  / Deep Learning | PyTorch 2.1 (GRU, MultiheadAttention, AdamW) |
| æœºå™¨å­¦ä¹ å·¥å…· / ML Utilities | scikit-learn (StandardScaler, KMeans, GroupKFold) |
| æ•°æ®å¤„ç† / Data | Pandas, NumPy |
| å¯è§†åŒ– / Visualization | Matplotlib, Seaborn |
| è¿è¡Œç¯å¢ƒ / Environment | Kaggle Notebooks (P100, 16 GB RAM) |

---


