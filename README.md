# ğŸŒ¿ CSIRO â€” Image2Biomass Prediction

> **åŸºäº DINOv3 ViT-Huge + SigLIP åŒè·¯é›†æˆçš„ç‰§è‰ç”Ÿç‰©é‡é¢„æµ‹ï¼ˆæ•´åˆä¼˜åŒ–ç‰ˆï¼‰**
>
> **Predicting five pasture biomass components via DINOv3 ViT-Huge + SigLIP / GBDT dual-route ensemble â€” Integrated & Optimized**
>
> Kaggle Competition Â· 2025.10â€“2026.01 Â· ğŸ¥ˆ é“¶ç‰Œ / Silver Medal Â· **Rank 82 / 3802ï¼ˆTop 2.2%ï¼‰**

[![Python](https://img.shields.io/badge/Python-3.10-blue.svg)](https://python.org)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.x-red.svg)](https://pytorch.org)
[![timm](https://img.shields.io/badge/timm-latest-orange.svg)](https://github.com/huggingface/pytorch-image-models)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Kaggle](https://img.shields.io/badge/Kaggle-Rank_82%2F3802_(Top_2.2%25)-blue.svg)](https://www.kaggle.com/competitions/csiro-biomass)
[![Medal](https://img.shields.io/badge/ğŸ¥ˆ_Silver_Medal-3802_Teams-silver.svg)]()
[![Score](https://img.shields.io/badge/LB_Score-0.64_(Weighted_RÂ²)-brightgreen.svg)]()

**ğŸŒ Language / è¯­è¨€ï¼šæœ¬æ–‡æ¡£ä¸ºä¸­è‹±æ–‡å¯¹ç…§ç‰ˆ â€” This document is bilingual (Chinese & English)**

---

## ğŸ“Œ é¡¹ç›®æ¦‚è¿° / Project Summary

### æ ¸å¿ƒè®¾è®¡ç†å¿µ / Core Design Philosophy

æœ¬æ–¹æ¡ˆèåˆã€Œç«èµ›çº§è½åœ°ç»†èŠ‚ã€ä¸ã€Œé€šç”¨æ–¹æ³•è®ºæ‹“å±•ã€ï¼Œå…¼é¡¾è½åœ°æ€§ä¸å¯è¿ç§»æ€§ï¼š**ä¿ç•™ç«èµ›ä¸­ç›´æ¥æ”¯æ’‘ ğŸ¥ˆ é“¶ç‰Œï¼ˆRank 82 / 3802ï¼‰çš„æ ¸å¿ƒå·¥ç¨‹ç­–ç•¥ï¼ŒåŒæ—¶å¼•å…¥é€šç”¨åŒ– / è‡ªåŠ¨åŒ–ä¼˜åŒ–ï¼Œè¡¥è¶³äººå·¥ç»éªŒä¾èµ–çš„çŸ­æ¿ã€‚**

This solution combines "competition-grade engineering details" with "generalizable methodology extensions": **retaining the core engineering strategies that directly supported the ğŸ¥ˆ Silver Medal (Rank 82 / 3802), while introducing automation to eliminate reliance on manual heuristics.**

- **ä¿ç•™ç«èµ›éªŒè¯çš„æ ¸å¿ƒä¼˜åŠ¿** â€” å®½å¹…å›¾åƒå·¦å³åˆ‡åˆ†ã€ç‰©ç†çº¦æŸåµŒå…¥æ¶æ„ã€DINO åƒç´ çº§ + SigLIP è¯­ä¹‰çº§åŒè·¯äº’è¡¥ï¼Œè¿™äº›ç­–ç•¥æ˜¯é“¶ç‰Œæˆç»©çš„ç›´æ¥æ”¯æ’‘ã€‚
- **Retain competition-validated core** â€” Wide-image left/right splitting, physics-constraint architecture, DINO pixel-level + SigLIP semantic-level dual-route: the direct foundation of the Silver Medal result.

- **è¡¥è¶³é€šç”¨åŒ– / è‡ªåŠ¨åŒ–çŸ­æ¿** â€” OOF ä¼˜åŒ–èåˆæƒé‡ï¼ˆæ›¿ä»£æ‰‹åŠ¨ 7:3ï¼‰ã€ç½‘æ ¼æœç´¢åå¤„ç†å‚æ•°ï¼ˆæ›¿ä»£ç»éªŒå€¼ï¼‰ã€å¯é…ç½®ç‰©ç†çº¦æŸå¤´ï¼ˆé€‚é…å¤šåœºæ™¯è¿ç§»ï¼‰ã€‚
- **Fill automation & generalization gaps** â€” OOF-optimized fusion weights (replacing manual 70/30), grid-search post-processing (replacing empirical values), configurable physics-constraint head (enabling multi-scenario transfer).

- **å¹³è¡¡ç«èµ›æè‡´æ€§ä¸åœºæ™¯é€šç”¨æ€§** â€” æ ¸å¿ƒæ¶æ„é€‚é…ç«èµ›çº¦æŸï¼ˆ9 å°æ—¶ GPUã€åŠ æƒ RÂ²ï¼‰ï¼ŒåŒæ—¶æŠ½è±¡é€šç”¨æ¨¡å—ï¼ˆå¯é…ç½®åˆ†å—ç­–ç•¥ã€å¤šåœºæ™¯ç‰©ç†çº¦æŸï¼‰ã€‚
- **Balance competition extremity and generalizability** â€” Core architecture fits competition constraints (9h GPU, weighted RÂ²), while abstracting universal modules (configurable splitting strategy, multi-scenario physics constraints).

### ä¸»è¦æ”¶è· / Key Takeaways

- **å·¦å³åˆ‡åˆ†æ˜¯å®½å¹…å›¾åƒçš„æœ€ä¼˜è§£** â€” 2:1 å®½å›¾ç›´æ¥ resize ä¼šä¸¥é‡å‹ç¼©æ°´å¹³çº¹ç†ï¼›åˆ‡æˆä¸¤ä¸ªæ­£æ–¹å½¢åˆ†åˆ«è¿‡ ViT å†åœ¨ token ç»´æ‹¼æ¥ï¼Œä»¥åŒå€æœ‰æ•ˆåˆ†è¾¨ç‡è¦†ç›–æ•´å›¾ï¼Œæ˜¯æœ¬æ–¹æ¡ˆå¤ºå–é“¶ç‰Œçš„å…³é”®å·¥ç¨‹å†³ç­–ã€‚
- **Left-right split is optimal for wide images** â€” 2:1 images resized directly lose horizontal texture; splitting into two squares, processed separately through ViT and token-concatenated, provides double effective resolution â€” a key engineering decision behind the Silver Medal.

- **ç‰©ç†çº¦æŸç¡¬ç¼–ç è¿›æ¶æ„** â€” ä»…æ˜¾å¼å›å½’ Green / Dead / Cloverï¼ŒGDM / Total åœ¨æ¨¡å‹å†…éƒ¨åŠ æ³•æ´¾ç”Ÿï¼Œä»æºå¤´æ¶ˆé™¤å¤šç›®æ ‡ç‰©ç†ä¸ä¸€è‡´ï¼Œé«˜æƒé‡ç›®æ ‡ï¼ˆTotal å  0.5ï¼‰ç›´æ¥å—ç›Šã€‚
- **Physics constraints hard-coded into architecture** â€” Only Green / Dead / Clover explicitly regressed; GDM / Total derived additively inside the model. High-weight target (Total at 0.5) directly benefits from eliminating physical inconsistency.

- **OOF é©±åŠ¨æ›¿ä»£äººå·¥ç»éªŒ** â€” å°†èåˆæƒé‡å’Œåå¤„ç†å‚æ•°ä»ç»éªŒå†³ç­–å‡çº§ä¸º OOF éªŒè¯çš„è‡ªåŠ¨æœç´¢ï¼Œåœ¨é“¶ç‰ŒåŸºç¡€ä¸Šè¿›ä¸€æ­¥æå‡çš„æ ¸å¿ƒç­–ç•¥ã€‚
- **OOF-driven automation over manual heuristics** â€” Upgrading fusion weights and post-processing from empirical decisions to OOF-validated automated search: the core strategy for further improvement beyond the Silver Medal.

- **SigLIP è¯­ä¹‰è¡¥å¿ DINO çš„ç›²åŒº** â€” æ¦‚å¿µå‘é‡ï¼ˆbare / dense / green / dead / cloverï¼‰å›¾æ–‡ç›¸ä¼¼åº¦ç‰¹å¾ï¼Œå¼¥è¡¥çº¯è§†è§‰å›å½’åœ¨æç«¯åœºæ™¯çš„æ³›åŒ–ä¸ç¨³å®šæ€§ã€‚
- **SigLIP semantic compensation for DINO blind spots** â€” Concept vector (bare / dense / green / dead / clover) image-text similarity features compensate for pure visual regression instability in extreme scenes.

---

## ğŸ“‹ ç›®å½• / Table of Contents

- [é¡¹ç›®æ¦‚è¿° / Project Summary](#-é¡¹ç›®æ¦‚è¿°--project-summary)
- [èµ›é¢˜èƒŒæ™¯ / Competition Background](#-èµ›é¢˜èƒŒæ™¯--competition-background)
- [æ–¹æ¡ˆæ¦‚è§ˆ / Solution Overview](#-æ–¹æ¡ˆæ¦‚è§ˆ--solution-overview)
- [å›¾åƒé¢„å¤„ç† / Image Preprocessing](#-å›¾åƒé¢„å¤„ç†--image-preprocessing)
- [åŒè·¯å»ºæ¨¡ / Two-Route Modeling](#-åŒè·¯å»ºæ¨¡--two-route-modeling)
- [æ¨¡å‹èåˆä¸åå¤„ç† / Model Fusion & Post-processing](#-æ¨¡å‹èåˆä¸åå¤„ç†--model-fusion--post-processing)
- [æ•´åˆæ–¹æ¡ˆæ ¸å¿ƒä¼˜åŠ¿ / Integrated Solution Advantages](#-æ•´åˆæ–¹æ¡ˆæ ¸å¿ƒä¼˜åŠ¿--integrated-solution-advantages)
- [å…³é”®å·¥ç¨‹å†³ç­– / Key Engineering Decisions](#-å…³é”®å·¥ç¨‹å†³ç­–--key-engineering-decisions)
- [ä»“åº“ç»“æ„ / Repository Structure](#-ä»“åº“ç»“æ„--repository-structure)
- [å¤ç°æŒ‡å— / Reproduction Guide](#-å¤ç°æŒ‡å—--reproduction-guide)
- [åæ€ä¸æœªæ¥æ–¹å‘ / Reflections & Future Directions](#-åæ€ä¸æœªæ¥æ–¹å‘--reflections--future-directions)

---

## ğŸ† ç«èµ›æˆç»© / Competition Result

| æŒ‡æ ‡ / Metric | æ•°å€¼ / Value |
|---|---|
| ğŸ¥ˆ **å¥–ç‰Œ / Medal** | **é“¶ç‰Œ / Silver Medal** |
| ğŸ… **æ’å / Rank** | **82 / 3802ï¼ˆTop 2.2%ï¼‰** |
| ğŸ“Š **LB åˆ†æ•° / LB Score** | **0.64ï¼ˆWeighted RÂ²ï¼‰** |
| ğŸ‘¥ **å‚èµ›é˜Ÿæ•° / Teams** | 3,802 |
| ğŸ“… **æ¯”èµ›å‘¨æœŸ / Period** | 2025.10 â€” 2026.01 |

> æœ¬æ–¹æ¡ˆåœ¨ 3802 æ”¯å‚èµ›é˜Ÿä¼ä¸­æ’åç¬¬ 82ï¼Œä½åˆ—å‰ 2.2%ï¼Œæ–©è· Kaggle é“¶ç‰Œã€‚æ•´åˆä¼˜åŒ–ç‰ˆåœ¨ç«èµ›è½åœ°ç‰ˆåŸºç¡€ä¸Šå¼•å…¥ OOF è‡ªåŠ¨åŒ–ä¼˜åŒ–ï¼Œé¢„æœŸ Weighted RÂ² å¯ä» **0.64 è¿›ä¸€æ­¥æå‡è‡³ 0.65+**ã€‚
>
> This solution ranked 82nd among 3,802 teams (Top 2.2%), earning a Kaggle Silver Medal. The integrated optimized version introduces OOF-based automation on top of the competition version, expected to further improve Weighted RÂ² from **0.64 to 0.65+**.

---

## ğŸŸ èµ›é¢˜èƒŒæ™¯ / Competition Background

**ä¸­æ–‡ï¼š**
CSIRO ç‰§è‰ç”Ÿç‰©é‡é¢„æµ‹ç«èµ›è¦æ±‚åˆ©ç”¨ç‰§åœºå®åœ°æ‹æ‘„å›¾åƒï¼Œé¢„æµ‹ 5 é¡¹å…³é”®ç”Ÿç‰©é‡æŒ‡æ ‡ã€‚å›¾åƒä¸ºå®½å¹…ç…§ç‰‡ï¼ˆçº¦ 2:1 æ¯”ä¾‹ï¼‰ï¼ŒçœŸå®æ ‡ç­¾ç”±å®åœ°å‰ªå‰²ç§°é‡è·å¾—ã€‚è¯„ä¼°æŒ‡æ ‡ä¸ºåŠ æƒ RÂ²ï¼ŒTotal æƒé‡é«˜è¾¾ 0.5ã€‚ä»£ç é¡»è¿è¡Œäº Kaggle Notebookï¼Œå•æ¬¡ GPU è¿è¡Œæ—¶é—´ä¸è¶…è¿‡ 9 å°æ—¶ã€‚

**English:**
The CSIRO Pasture Biomass Prediction competition requires predicting five key biomass components from field-captured pasture images (~2:1 aspect ratio). Labels come from physical cut-and-weigh. The metric is weighted RÂ² with Dry_Total_g carrying the highest weight at 0.5. Code must run within a Kaggle Notebook (â‰¤ 9 h GPU).

**è¯„ä¼°æƒé‡ / Evaluation Weightsï¼š**

| ç›®æ ‡ / Target | æƒé‡ / Weight | ç‰©ç†å…³ç³» / Physics Relation |
|---|---|---|
| `Dry_Green_g` | 0.1 | åŸºç¡€åˆ†é‡ / Base |
| `Dry_Dead_g` | 0.1 | åŸºç¡€åˆ†é‡ / Base |
| `Dry_Clover_g` | 0.1 | åŸºç¡€åˆ†é‡ / Base |
| `GDM_g` | 0.2 | = Green + Cloverï¼ˆæ´¾ç”Ÿ / Derivedï¼‰|
| `Dry_Total_g` | **0.5** | = GDM + Deadï¼ˆæ´¾ç”Ÿ / Derivedï¼‰|

**ä¸»è¦æŒ‘æˆ˜ / Key Challengesï¼š**

| æŒ‘æˆ˜ / Challenge | è¯´æ˜ / Description |
|---|---|
| å®½å¹…å›¾åƒè¾“å…¥ / Wide-aspect images | æ ‡å‡† ViT æ–¹å½¢è¾“å…¥ä¸ 2:1 æ¯”ä¾‹ä¸åŒ¹é…ï¼›ç›´æ¥ resize ä¸¢å¤±å¤§é‡æ°´å¹³çº¹ç† / Standard ViT mismatches 2:1 ratio; direct resize loses horizontal texture |
| ç›®æ ‡é—´ç‰©ç†çº¦æŸ / Physics constraints | GDM / Total ä¸ºæ´¾ç”Ÿé‡ï¼Œç‹¬ç«‹å›å½’éš¾ä»¥ä¿è¯ä¸€è‡´æ€§ / GDM / Total are derived; independent regression risks physical inconsistency |
| Clover ä¿¡å·ç¨€ç¼º / Sparse Clover signal | è‹œè“¿å›¾åƒå æ¯”å°ã€è§†è§‰ç‰¹å¾å¾®å¼±ï¼Œæ˜¯äº”ä¸ªåˆ†é‡ä¸­æœ€éš¾å›å½’çš„ / Clover has small area and weak visual features; hardest target to regress |
| æ ‡ç­¾å™ªå£° / Label noise | å®åœ°å‰ªå‰²ç§°é‡å­˜åœ¨æµ‹é‡è¯¯å·®ï¼Œéœ€è¦é²æ£’æŸå¤±å‡½æ•° / Cut-and-weigh labels contain measurement noise; robust loss is critical |
| è¿è¡Œæ—¶é—´çº¦æŸ / Runtime constraint | åŒè·¯æ¨ç†é¡»åœ¨ 9 å°æ—¶å†…å®Œæˆï¼Œæ¥è¿‘ä¸Šé™ / Two-route inference must fit within 9 hours |

---

## ğŸŒŸ æ–¹æ¡ˆæ¦‚è§ˆ / Solution Overview

```
æ ¸å¿ƒæ´å¯Ÿ / Key Insight:
  åŒä¸€å¼ ç‰§åœºå›¾ï¼ŒDINO çœ‹åˆ°åƒç´ çº§çº¹ç†ä¸ç©ºé—´ç»“æ„ï¼ŒSigLIP çœ‹åˆ°è¯­ä¹‰å±‚é¢çš„æ¤è¢«ç±»åˆ«ã€‚
  ä¸¤è·¯ç‹¬ç«‹é¢„æµ‹ï¼ŒOOF è‡ªåŠ¨ä¼˜åŒ–æƒé‡èåˆï¼Œæ¯”ä»»ä½•å•è·¯éƒ½æ›´ç¨³å¥ã€‚
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  The same pasture image looks different to DINO (pixel-level texture & structure)
  vs. SigLIP (semantic vegetation categories).
  Two independent routes, OOF-optimized weighted fusion, outperforms any single route.
```

| ç»„ä»¶ / Component | ç«èµ›è½åœ°ç‰ˆï¼ˆé“¶ç‰Œï¼‰/ Competition Version (Silver) | æ•´åˆä¼˜åŒ–ç‰ˆ / Optimized Version |
|---|---|---|
| **å›¾åƒåˆ†å—** | å›ºå®šå·¦å³åˆ‡åˆ† | å¯é…ç½®ä¸‰æ¨¡å¼ï¼šå·¦å³ / æ»‘åŠ¨çª—å£ / å¤šå°ºåº¦ |
| **Image splitting** | Fixed left-right split | Configurable 3-mode: left-right / sliding window / multi-scale |
| **è·¯çº¿ A è¾“å‡ºå¤´** | å›ºå®šä¸‰å¤´ï¼ˆGreen/Dead/Cloverï¼‰| å¯é…ç½®ç‰©ç†çº¦æŸå¤´ `PhysicsConstrainedHead` |
| **Route A output head** | Fixed 3-head | Configurable `PhysicsConstrainedHead` |
| **Clover ç­–ç•¥** | å•ä¸€ä¸»å¤´ + åå¤„ç† Ã—0.8 | ä¸»å¤´ + ä¸“é¡¹åˆ†æ”¯åŠ æƒ + è‡ªåŠ¨ç¼©æ”¾æœç´¢ |
| **Clover strategy** | Single head + post-proc Ã—0.8 | Main head + dedicated branch + auto scale search |
| **è·¯çº¿ B GBDT** | 4 æ¨¡å‹é›†æˆï¼ˆ~4hï¼‰| è½»é‡åŒ– 2 æ¨¡å‹ + OOF åŠ æƒï¼ˆ~2hï¼‰|
| **Route B GBDT** | 4-model ensemble (~4h) | Lightweight 2-model + OOF weighted (~2h) |
| **èåˆæƒé‡** | æ‰‹åŠ¨ DINO 70% / SigLIP 30% | OOF æ¢¯åº¦æœç´¢è‡ªåŠ¨ä¼˜åŒ– |
| **Fusion weights** | Manual DINO 70% / SigLIP 30% | OOF gradient-search auto-optimization |
| **åå¤„ç†å‚æ•°** | ç»éªŒå€¼ï¼ˆCloverÃ—0.8, Dead é˜ˆå€¼å›ºå®šï¼‰| ç½‘æ ¼æœç´¢ + OOF éªŒè¯ |
| **Post-processing** | Empirical (fixed CloverÃ—0.8, Dead thresholds) | Grid search + OOF validation |
| **è¯„ä¼°é²æ£’æ€§** | æ—  OOF èåˆè¯„ä¼° | å…¨æµç¨‹ OOF éªŒè¯ |
| **Eval robustness** | No OOF fusion evaluation | Full-pipeline OOF validation |
| **è¿è¡Œæ—¶é—´** | æ¥è¿‘ 9 å°æ—¶ | ä¼˜åŒ–è‡³ ~7 å°æ—¶ï¼Œé¢„ç•™ TTA ç©ºé—´ |
| **Runtime** | Near 9h limit | Optimized to ~7h, leaving room for TTA |

### ç®—æ³•æµç¨‹å›¾ / Pipeline Diagram

```mermaid
flowchart TD
    A["ğŸ“· è¾“å…¥å›¾åƒ\nRaw Pasture Image (wide ~2:1)"]

    A --> B["âœ‚ï¸ å¯é…ç½®åˆ†å—ç­–ç•¥\nConfigurable Split Mode\nå·¦å³åˆ‡åˆ† Â· æ»‘åŠ¨çª—å£ Â· å¤šå°ºåº¦"]
    B --> C["ğŸ”„ å„å— Resize 512Ã—512\nImageNet Normalization"]

    C --> D["è·¯çº¿A / Route A\nDINOv3 ViT-Huge Backbone"]
    A --> E["è·¯çº¿B / Route B\nSigLIP Patch Embeddings"]

    D --> F["LocalMamba èåˆï¼ˆ2Ã—ï¼‰\n2Ã— LocalMambaBlock on token seq [2L, C]"]
    F --> G["å¯é…ç½®ç‰©ç†çº¦æŸå¤´\nPhysicsConstrainedHead\nGreen / Dead / Cloverï¼ˆåŸºç¡€åˆ†é‡ï¼‰\nâ†’ GDM / Totalï¼ˆæ´¾ç”Ÿï¼‰"]
    G --> G2["Clover ä¸“é¡¹åˆ†æ”¯ âœ¦æ–°å¢\nColor-range Patch â†’ LightViT\nä¸»å¤´ Ã— 0.8 + ä¸“é¡¹ Ã— 0.2"]
    G2 --> H["OOF ç½‘æ ¼æœç´¢åå¤„ç† âœ¦æ–°å¢\nAuto-tuned: Clover_scale Â· Dead_thresholds\nâ†’ è´¨é‡å¹³è¡¡é‡ç®— Â· éè´Ÿæˆªæ–­"]

    E --> J["æ»‘åŠ¨çª—å£åˆ‡ç‰‡åµŒå…¥\nSigLIP Patch-mean Embeddings (1152-d)"]
    J --> K["è‡ªåŠ¨æ‰©å±•è¯­ä¹‰ç‰¹å¾ âœ¦æ–°å¢\nAuto-expanded Concepts\nbare Â· sparse Â· dense Â· green Â· dead Â· clover"]
    K --> L["ç›‘ç£åµŒå…¥å¼•æ“\nPCA(80%) + PLS(8) + GMM(6) + Semantic"]
    L --> M["è½»é‡åŒ– GBDTï¼ˆ2 æ¨¡å‹ï¼‰âœ¦ä¼˜åŒ–\nLightGBM + CatBoost\nOOF åŠ æƒèåˆ"]

    H --> N["âš–ï¸ OOF ä¼˜åŒ–èåˆæƒé‡ âœ¦æ–°å¢\nscipy.optimize â†’ auto w_DINO / w_SigLIP\nClover: DINO only"]
    M --> N

    N --> O["é€šç”¨è´¨é‡å¹³è¡¡ä¿®æ­£\nmass_balance_correction(derived_mapping)\n+ éè´Ÿæˆªæ–­"]
    O --> P["ğŸ“„ submission.csv\nğŸ¥ˆ Rank 82 / 3802 Â· LB 0.64"]
```

---

## ğŸ–¼ å›¾åƒé¢„å¤„ç† / Image Preprocessing

### 1.1 åŸºç¡€ç­–ç•¥ï¼ˆä¿ç•™ç«èµ›éªŒè¯ç‰ˆï¼‰/ Base Strategy (Retained from Competition)

å®½å¹…ç‰§åœºå›¾åƒï¼ˆçº¦ 2:1ï¼‰ä»å·¦å³å„è£å‡ºä¸€ä¸ªæ­£æ–¹å½¢åŒºåŸŸï¼Œåˆ†åˆ« resize è‡³ 512Ã—512 åå„è‡ªè¿‡ ViT backboneï¼Œå†åœ¨ token ç»´åº¦æ‹¼æ¥èåˆã€‚**è¿™ä¸€ç­–ç•¥åœ¨é“¶ç‰Œæ–¹æ¡ˆä¸­ç›´æ¥æ”¯æ’‘äº†å®½å¹…å›¾åƒçš„æœ‰æ•ˆè¡¨è¾¾ã€‚**

Wide pasture images (~2:1) are cropped into two square regions from left and right ends, each resized to 512Ã—512 and processed through the ViT backbone, then concatenated in the token dimension. **This strategy directly supported effective wide-image representation in the Silver Medal solution.**

```
åŸå›¾ (W Ã— H, Wâ‰ˆ2H)             å·¦åŠå¹… (HÃ—H)              å³åŠå¹… (HÃ—H)
Raw Image (W Ã— H)    â†’    Left (0, 0, H, H)    +    Right (W-H, 0, W, H)
                                â†“                             â†“
                          Resize 512Ã—512              Resize 512Ã—512
                                â†“                             â†“
                       ViT-Huge Backbone           ViT-Huge Backbone
                                â†“                             â†“
                          Tokens [L, C]              Tokens [L, C]
                                â””â”€â”€â”€â”€â”€â”€â”€â”€ Cat â†’ [2L, C] â”€â”€â”€â”€â”€â”€â”˜
                                                 â†“
                                       LocalMamba Fusion (2Ã—)
                                                 â†“
                                     AdaptiveAvgPool â†’ [C]
                                                 â†“
                              Green / Dead / Clover Heads
```

### 1.2 é€šç”¨åŒ–æ‹“å±•ï¼ˆæ•´åˆç‰ˆæ–°å¢ï¼‰/ Generalized Extension (New in Integrated Version)

å¯é…ç½®åˆ†å—ç­–ç•¥ï¼Œæ”¯æŒä¸‰ç§æ¨¡å¼é€šè¿‡å‚æ•°åˆ‡æ¢ï¼Œé€‚é… 3:1 / 4:1 ç­‰ä¸åŒå®½é«˜æ¯”å›¾åƒï¼š

Configurable split strategy supporting three modes switchable by parameter, adapting to 3:1 / 4:1 and other aspect ratios:

```python
def split_wide_image(img, split_mode="left_right", target_size=512):
    h, w = img.shape[:2]
    if split_mode == "left_right":
        # ç«èµ›è½åœ°ç‰ˆï¼šå·¦å³å„è£ä¸€ä¸ªæ­£æ–¹å½¢ / Competition version
        left  = img[:, :h, :]
        right = img[:, w-h:, :]
        return [cv2.resize(left,  (target_size, target_size)),
                cv2.resize(right, (target_size, target_size))]

    elif split_mode == "sliding_window":
        # é€šç”¨æ»‘åŠ¨çª—å£ï¼Œé€‚é…ä»»æ„å®½é«˜æ¯” / Universal sliding window for any aspect ratio
        patches, step = [], target_size // 2
        for x in range(0, w - target_size + 1, step):
            patch = img[:, x:x + target_size, :]
            patches.append(cv2.resize(patch, (target_size, target_size)))
        return patches

    elif split_mode == "multi_scale":
        # å…¨å›¾ä½åˆ†è¾¨ç‡ + å±€éƒ¨é«˜åˆ†è¾¨ç‡åŒè·¯ / Global low-res + local high-res dual
        global_patch  = cv2.resize(img, (target_size, target_size))
        local_patches = split_wide_image(img, "left_right", target_size)
        return [global_patch] + local_patches
```

### è®­ç»ƒæ•°æ®å¢å¼º / Training Augmentation

| å¢å¼ºæ–¹å¼ / Augmentation | æ¦‚ç‡ / Probability | è¯´æ˜ / Notes |
|---|---|---|
| `HorizontalFlip` | 0.5 | æ°´å¹³ç¿»è½¬ |
| `VerticalFlip` | 0.5 | å‚ç›´ç¿»è½¬ |
| `RandomRotate90` | 0.5 | éšæœº 90Â° æ—‹è½¬ |
| `ShiftScaleRotate` | 0.5 | å¹³ç§» Â±10% / ç¼©æ”¾ Â±10% / æ—‹è½¬ Â±15Â° |
| `ColorJitter` | 0.3 | äº®åº¦ / å¯¹æ¯”åº¦ / é¥±å’Œåº¦ / è‰²è°ƒæ‰°åŠ¨ |
| `Normalize` | 1.0 | ImageNet å‡å€¼æ–¹å·®å½’ä¸€åŒ– |

---

## ğŸ”¬ åŒè·¯å»ºæ¨¡ / Two-Route Modeling

### è·¯çº¿ Aï¼šDINOv3 ViT-Huge å¾®è°ƒ / Route A: DINOv3 ViT-Huge Fine-tuning

**Backboneï¼š** `vit_huge_plus_patch16_dinov3.lvd1689m`ï¼ˆtimmï¼Œé¢„è®­ç»ƒäº LVD-1689Mï¼Œçº¦ 1.1B å‚æ•°ï¼‰

#### ä¿ç•™çš„ç«èµ›æ ¸å¿ƒ / Retained Competition Core

- LocalMambaBlock èåˆæ¨¡å—ï¼ˆ2 å±‚ï¼Œkernel_size=5ï¼Œé—¨æ§ + æ·±åº¦å¯åˆ†ç¦»å·ç§¯ï¼‰
- ç‰©ç†çº¦æŸè¾“å‡ºå¤´ï¼ˆä»…å›å½’ Green / Dead / Cloverï¼ŒGDM / Total åŠ æ³•æ´¾ç”Ÿï¼‰
- å·®åˆ†å­¦ä¹ ç‡ï¼šbackbone 1Ã—10â»âµï¼Œhead 5Ã—10â»â´
- Warmupï¼ˆ2 epochï¼‰+ ä½™å¼¦é€€ç«ï¼ˆæŒ‰ step æ›´æ–°ï¼‰
- `SmoothL1Loss(beta=5.0)`
- 4 æŠ˜ `StratifiedGroupKFold`ï¼ˆåˆ†å±‚ Total åˆ†ä½ + åˆ†ç»„ image_idï¼‰

#### å¯é…ç½®ç‰©ç†çº¦æŸå¤´ï¼ˆæ•´åˆç‰ˆï¼‰/ Configurable Physics-Constrained Head (Integrated)

å°†åŸæ–¹æ¡ˆå›ºå®šä¸‰å¤´ç»“æ„æ³›åŒ–ä¸ºå¯é…ç½®æ¨¡å—ï¼Œæ”¯æŒè‡ªå®šä¹‰ã€ŒåŸºç¡€åˆ†é‡ + æ´¾ç”Ÿåˆ†é‡ã€æ˜ å°„å…³ç³»ï¼Œé€‚é…ä¸åŒç‰©ç†çº¦æŸåœºæ™¯ï¼ˆå¦‚é¢ç§¯ = é•¿ Ã— å®½ã€ä½“ç§¯ = é•¿ Ã— å®½ Ã— é«˜ï¼‰ï¼š

Generalizing the original fixed three-head structure to a configurable module supporting custom "base + derived" mapping, adaptable to different physics-constraint scenarios:

```python
class PhysicsConstrainedHead(nn.Module):
    def __init__(self, in_dim, base_targets, derived_mapping):
        super().__init__()
        # åŸºç¡€åˆ†é‡å¤´ï¼ˆSoftplus ä¿è¯éè´Ÿï¼‰/ Base heads (Softplus for non-negativity)
        self.base_heads = nn.ModuleDict({
            t: nn.Sequential(
                nn.Linear(in_dim, in_dim // 2), nn.GELU(), nn.Dropout(0.2),
                nn.Linear(in_dim // 2, 1), nn.Softplus()
            ) for t in base_targets
        })
        self.derived_mapping = derived_mapping  # {"GDM": ["Green","Clover"], ...}

    def forward(self, x):
        base_preds    = {t: head(x) for t, head in self.base_heads.items()}
        derived_preds = {der: sum(base_preds[b] for b in bases)
                         for der, bases in self.derived_mapping.items()}
        return {**base_preds, **derived_preds}

# ç‰§è‰åœºæ™¯å®ä¾‹åŒ– / Pasture scenario instantiation
head = PhysicsConstrainedHead(
    in_dim=1280,
    base_targets=["Dry_Green_g", "Dry_Dead_g", "Dry_Clover_g"],
    derived_mapping={
        "GDM_g":       ["Dry_Green_g", "Dry_Clover_g"],  # GDM = Green + Clover
        "Dry_Total_g": ["GDM_g",       "Dry_Dead_g"]     # Total = GDM + Dead
    }
)
```

#### Clover ä¸“é¡¹åˆ†æ”¯ï¼ˆæ•´åˆç‰ˆæ–°å¢ï¼‰/ Clover-dedicated Branch (New)

é’ˆå¯¹ Clover ä¿¡å·å¾®å¼±çš„é—®é¢˜ï¼Œæ–°å¢åŸºäºè‰²åŸŸç­›é€‰çš„ä¸“é¡¹ç‰¹å¾åˆ†æ”¯ï¼Œå•ç‹¬å¼ºåŒ–è‹œè“¿ç‰¹å¾å­¦ä¹ ï¼›æœ€ç»ˆ Clover ç”±ä¸»å¤´ä¸ä¸“é¡¹åˆ†æ”¯åŠ æƒèåˆï¼š

A color-range-based dedicated feature branch for Clover, separately strengthening clover feature learning; final Clover is a weighted fusion of the main head and dedicated branch:

```python
# è‹œè“¿è‰²åŸŸ patch æå–ï¼ˆç»¿ç™½è‰²åŸŸ HSV ç­›é€‰ï¼‰/ Clover patch extraction (green-white HSV)
clover_patches = extract_clover_patches(img, color_range=(0,255, 0,255, 200,255))
clover_feat    = vit_mini(clover_patches)          # è½»é‡ ViT æå–å±€éƒ¨ç‰¹å¾
clover_branch  = nn.Linear(clover_feat.shape[-1], 1)(clover_feat)

# ä¸»å¤´ Ã— 0.8 + ä¸“é¡¹åˆ†æ”¯ Ã— 0.2ï¼ˆæ›¿ä»£åŸç«èµ›ç‰ˆçº¯ Ã—0.8 åå¤„ç†ï¼‰
final_clover = 0.8 * base_clover + 0.2 * clover_branch
```

**è®­ç»ƒé…ç½®å¯¹æ¯” / Training Configuration Comparisonï¼š**

| é…ç½®é¡¹ / Config | ç«èµ›ç‰ˆï¼ˆé“¶ç‰Œï¼‰/ Competition | æ•´åˆä¼˜åŒ–ç‰ˆ / Optimized |
|---|---|---|
| Backbone | `vit_huge_plus_patch16_dinov3` | åŒå·¦ / Same |
| è¾“å…¥åˆ†è¾¨ç‡ | 512Ã—512ï¼ˆå›ºå®šï¼‰| 512 / 384 / 256 å¤šå°ºåº¦éšæœº |
| Batch size | 6 | 6ï¼ˆæ¢¯åº¦ç´¯ç§¯ Ã—2 = ç­‰æ•ˆ 12ï¼‰|
| æœ€å¤§ Epoch | 210 | 180ï¼ˆæ¢¯åº¦ç´¯ç§¯ç¼©çŸ­ + æ—©åœ patience=15ï¼‰|
| æŸå¤± | `SmoothL1Loss(Î²=5.0)` | åŒå·¦ + è‡ªé€‚åº”åˆ†é‡æƒé‡ |
| OOF è¾“å‡º | âŒ | âœ…ï¼ˆä¾›èåˆæƒé‡ä¼˜åŒ–ä½¿ç”¨ï¼‰|

---

### è·¯çº¿ Bï¼šSigLIP + ç›‘ç£åµŒå…¥å¼•æ“ + GBDT / Route B: SigLIP + Supervised Embedding Engine + GBDT

#### ä¿ç•™çš„ç«èµ›æ ¸å¿ƒ / Retained Competition Core

SigLIP æ»‘åŠ¨çª—å£ patch åµŒå…¥ï¼ˆpatch_size=520, overlap=16ï¼‰â†’ è¯­ä¹‰æ¦‚å¿µç›¸ä¼¼åº¦ç‰¹å¾ï¼ˆbare / sparse / dense / green / dead / cloverï¼‰â†’ ç›‘ç£åµŒå…¥å¼•æ“ï¼ˆPCA 80% + PLS 8 + GMM 6ï¼‰â†’ GBDT é›†æˆ

#### è‡ªåŠ¨æ‰©å±•è¯­ä¹‰ Promptï¼ˆæ•´åˆç‰ˆï¼‰/ Auto-expanded Semantic Prompts (Integrated)

åŸæ–¹æ¡ˆæ‰‹åŠ¨å›ºå®š 8 ä¸ªæ¦‚å¿µ promptï¼›æ•´åˆç‰ˆé€šè¿‡è‡ªåŠ¨ç¿»è¯‘ + å˜ä½“ç”Ÿæˆï¼Œæ‰©å……æ¦‚å¿µåº“è¦†ç›–åº¦ï¼š

Original: 8 manually fixed concept prompts; integrated: auto-translation + variant generation for expanded coverage:

```python
def auto_expand_semantic_prompts(base_prompts, langs=["en", "zh"]):
    """è‡ªåŠ¨ç¿»è¯‘ + å˜ä½“ç”Ÿæˆï¼ŒåŸ 8 æ¦‚å¿µ â†’ æ‰©å±•è‡³ 40+ å˜ä½“"""
    expanded = []
    for prompt in base_prompts:
        for lang in langs:
            t = translate(prompt, dest=lang)
            expanded += [t, f"high density {t}", f"low density {t}"]
    return list(set(expanded))

# åŸ 8 ä¸ªæ¦‚å¿µ â†’ è‡ªåŠ¨æ‰©å±•ä¸º 40+ å˜ä½“ prompt
concepts_expanded = auto_expand_semantic_prompts([
    "bare soil", "sparse pasture", "dense pasture", "green vegetation",
    "dead grass", "white clover", "ryegrass", "trifolium repens"
])
```

#### è½»é‡åŒ– GBDT é›†æˆï¼ˆæ•´åˆç‰ˆï¼‰/ Lightweight GBDT Ensemble (Integrated)

åŸæ–¹æ¡ˆ 4 ä¸ªæ¨¡å‹è¿è¡Œçº¦ 4 å°æ—¶ï¼›æ•´åˆç‰ˆç²¾ç®€ä¸º 2 ä¸ªæ ¸å¿ƒæ¨¡å‹ï¼Œé‡‡ç”¨ OOF åŠ æƒèåˆï¼ŒèŠ‚çœçº¦ 2 å°æ—¶ï¼š

Original 4 models took ~4 hours; integrated version reduces to 2 core models with OOF weighted fusion, saving ~2 hours:

| æ¨¡å‹ / Model | ç«èµ›ç‰ˆ / Competition | æ•´åˆç‰ˆ / Optimized | å…³é”®è¶…å‚ / Key Params |
|---|---|---|---|
| `HistGradientBoostingRegressor` | âœ… | âŒ ç§»é™¤ | â€” |
| `GradientBoostingRegressor` | âœ… | âŒ ç§»é™¤ | â€” |
| `CatBoostRegressor` | âœ… | âœ… ä¿ç•™ | iterations=1900, lr=0.045, depth=4 |
| `LGBMRegressor` | âœ… | âœ… ä¿ç•™ | n_estimators=807, lr=0.014, num_leaves=48 |
| **èåˆæ–¹å¼** | ç®€å•å¹³å‡ | **OOF åŠ æƒèåˆ** | â€” |

---

## âš–ï¸ æ¨¡å‹èåˆä¸åå¤„ç† / Model Fusion & Post-processing

### æ ¸å¿ƒä¼˜åŒ–ï¼šOOF è‡ªåŠ¨ä¼˜åŒ–èåˆæƒé‡ / Core Upgrade: OOF Auto-optimized Fusion Weights

å°†ç«èµ›ç‰ˆæ‰‹åŠ¨è®¾å®šçš„ DINO 70% / SigLIP 30% å‡çº§ä¸ºåŸºäº 4 æŠ˜ OOF é¢„æµ‹çš„æ¢¯åº¦æœç´¢è‡ªåŠ¨ä¼˜åŒ–ï¼š

Upgrading the competition version's manual DINO 70% / SigLIP 30% to gradient-search auto-optimization based on 4-fold OOF predictions:

```python
from scipy.optimize import minimize

def weight_loss(weights, dino_oof, siglip_oof, labels,
                r2_weights=[0.1, 0.1, 0.1, 0.2, 0.5]):
    """æœ€å°åŒ–è´ŸåŠ æƒ RÂ²ï¼Œå³æœ€å¤§åŒ–ç«èµ›è¯„åˆ† / Minimize negative weighted RÂ²"""
    w = weights[0]
    fusion_pred  = w * dino_oof + (1 - w) * siglip_oof
    r2_scores    = [r2_score(labels[t], fusion_pred[t]) for t in labels.columns]
    weighted_r2  = sum(r * wt for r, wt in zip(r2_scores, r2_weights))
    return -weighted_r2

result = minimize(
    weight_loss,
    x0=[0.7],                           # åˆå§‹å€¼ï¼šç«èµ›ç‰ˆæƒé‡ / Init: competition weight
    args=(dino_oof, siglip_oof, labels),
    bounds=[(0, 1)],
    constraints=[{'type': 'ineq', 'fun': lambda x: x[0]},
                 {'type': 'ineq', 'fun': lambda x: 1 - x[0]}]
)
opt_w_dino, opt_w_siglip = result.x[0], 1 - result.x[0]
```

### åå¤„ç†è‡ªåŠ¨åŒ–ï¼šç½‘æ ¼æœç´¢ + OOF éªŒè¯ / Post-processing Automation: Grid Search + OOF

å°†ç«èµ›ç‰ˆç»éªŒæ€§çš„ `Clover Ã— 0.8` å’Œå›ºå®š Dead é˜ˆå€¼ï¼ˆ10 / 20ï¼‰æ›¿æ¢ä¸ºç³»ç»ŸåŒ–ç½‘æ ¼æœç´¢ï¼š

Replacing the competition version's empirical `Clover Ã— 0.8` and fixed Dead thresholds (10 / 20) with systematic grid search:

```python
best_r2, best_params = -1, {}
clover_scales    = [0.70, 0.75, 0.80, 0.85, 0.90]
dead_thresholds  = [(8, 18), (10, 20), (12, 22)]
dead_scale_pairs = [(0.85, 1.15), (0.90, 1.10), (0.95, 1.05)]

for c_scale in clover_scales:
    for (d_low, d_high) in dead_thresholds:
        for (s_low, s_high) in dead_scale_pairs:
            pred = dino_oof.copy()
            pred['Dry_Clover_g'] *= c_scale
            pred.loc[pred['Dry_Dead_g'] < d_low,  'Dry_Dead_g'] *= s_low
            pred.loc[pred['Dry_Dead_g'] > d_high, 'Dry_Dead_g'] *= s_high
            score = calc_weighted_r2(pred, labels)
            if score > best_r2:
                best_r2, best_params = score, dict(
                    clover_scale=c_scale, dead_low=d_low,
                    dead_high=d_high, scale_low=s_low, scale_high=s_high)
```

### é€šç”¨è´¨é‡å¹³è¡¡ä¿®æ­£ / Universal Mass-Balance Correction

å°†ç«èµ›ç‰ˆç¡¬ç¼–ç çš„è´¨é‡å¹³è¡¡ä¿®æ­£å°è£…ä¸ºé€šç”¨å‡½æ•°ï¼Œé€‚é…ä»»æ„ç‰©ç†æ´¾ç”Ÿå…³ç³»ï¼š

Encapsulating the competition version's hard-coded mass-balance correction into a universal function:

```python
def mass_balance_correction(preds, derived_mapping):
    """é€šç”¨ç‰©ç†å¹³è¡¡ä¿®æ­£ + éè´Ÿæˆªæ–­ / Universal physics-balance correction + non-negative clip"""
    for derived, bases in derived_mapping.items():
        preds[derived] = sum(preds[b] for b in bases)
    for col in preds.columns:
        preds[col] = preds[col].clip(lower=0.0)
    return preds

# ç‰§è‰åœºæ™¯è°ƒç”¨ / Pasture scenario call
final = mass_balance_correction(final, {
    "GDM_g":       ["Dry_Green_g", "Dry_Clover_g"],
    "Dry_Total_g": ["GDM_g",       "Dry_Dead_g"]
})
```

---

## ğŸˆ æ•´åˆæ–¹æ¡ˆæ ¸å¿ƒä¼˜åŠ¿ / Integrated Solution Advantages

| ç»´åº¦ / Dimension | ç«èµ›è½åœ°ç‰ˆï¼ˆğŸ¥ˆ é“¶ç‰Œï¼‰/ Competition (Silver) | æ•´åˆä¼˜åŒ–ç‰ˆ / Optimized |
|---|---|---|
| **è½åœ°æ€§ / Deployability** | æå¼ºï¼Œç›´æ¥æ”¯æ’‘ Rank 82 / 3802 | å¼ºï¼Œä¿ç•™æ ¸å¿ƒè½åœ°ç»†èŠ‚ï¼Œä¼˜åŒ–è¿è¡Œæ—¶é—´ |
| **è‡ªåŠ¨åŒ–ç¨‹åº¦ / Automation** | ä½ï¼ˆæ‰‹åŠ¨æƒé‡ / ç»éªŒåå¤„ç†ï¼‰| é«˜ï¼ˆOOF ä¼˜åŒ–æƒé‡ã€ç½‘æ ¼æœç´¢åå¤„ç†ï¼‰|
| **é€šç”¨å¯è¿ç§»æ€§ / Transferability** | å¼±ï¼ˆä»…é€‚é…ç‰§è‰åœºæ™¯ï¼‰| å¼ºï¼ˆå¯é…ç½®ç‰©ç†çº¦æŸã€åˆ†å—ç­–ç•¥ã€è¯­ä¹‰ç‰¹å¾ï¼‰|
| **Clover é¢„æµ‹èƒ½åŠ›** | å¼±ï¼ˆç³»ç»Ÿæ€§é«˜ä¼°ï¼Œåå¤„ç†ä¿®æ­£ï¼‰| ä¸­ï¼ˆä¸“é¡¹åˆ†æ”¯ + è‡ªåŠ¨åŒ–ç¼©æ”¾æœç´¢ï¼‰|
| **è¿è¡Œæ—¶é—´ / Runtime** | æ¥è¿‘ 9 å°æ—¶ä¸Šé™ | ~7 å°æ—¶ï¼Œé¢„ç•™ TTA ç©ºé—´ |
| **è¯„ä¼°é²æ£’æ€§ / Eval robustness** | æ—  OOF èåˆè¯„ä¼° | å…¨æµç¨‹ OOF éªŒè¯ |
| **é¢„æœŸ LB åˆ†æ•° / Expected LB** | **0.64ï¼ˆå·²éªŒè¯ï¼‰** | **0.65+ï¼ˆé¢„æœŸï¼‰** |

---

## ğŸ›  å…³é”®å·¥ç¨‹å†³ç­– / Key Engineering Decisions

### 1. å·®åˆ†å­¦ä¹ ç‡ + Warmup ä½™å¼¦é€€ç« / Differential LR + Warmup Cosine Annealing

å¤§æ¨¡å‹å¾®è°ƒä¸­ï¼Œbackbone ä½¿ç”¨å°å­¦ä¹ ç‡é˜²æ­¢ç¾éš¾æ€§é—å¿˜ï¼Œhead ä½¿ç”¨å¤§å­¦ä¹ ç‡å¿«é€Ÿé€‚é…ä»»åŠ¡ï¼š

```python
optimizer = AdamW([
    {'params': backbone_params, 'lr': 1e-5},   # ä¸»å¹²ï¼šé˜²æ­¢ç¾éš¾æ€§é—å¿˜
    {'params': head_params,     'lr': 5e-4},   # å¤´éƒ¨ï¼šå¿«é€Ÿé€‚é…å›å½’ä»»åŠ¡
], weight_decay=1e-2)

# æŒ‰ step æ›´æ–°ï¼š2 epoch çº¿æ€§ warmup â†’ ä½™å¼¦é€€ç«è‡³é›¶
lr_fn = lambda step: (
    step / warmup_steps if step < warmup_steps else
    0.5 * (1 + cos(Ï€ * (step - warmup_steps) / (total_steps - warmup_steps)))
)
```

### 2. SmoothL1Loss (Î²=5.0) çš„æŠ—å™ªé€‰æ‹© / SmoothL1Loss (Î²=5.0) for Noise Robustness

å®åœ°å‰ªå‰²ç§°é‡æ ‡ç­¾å«æµ‹é‡è¯¯å·®ã€‚`SmoothL1Loss(beta=5.0)` åœ¨è¯¯å·®å°äº 5g æ—¶ä½¿ç”¨å¹³æ–¹æŸå¤±ï¼ˆç²¾ç»†æ‹Ÿåˆï¼‰ï¼Œå¤§äº 5g æ—¶åˆ‡æ¢ä¸ºçº¿æ€§æŸå¤±ï¼ˆæŠ—ç¦»ç¾¤ç‚¹ï¼‰ï¼š

```
è¯¯å·® < 5g â†’ 0.5 Ã— errorÂ² / Î²   (ç²¾ç»†æ‹Ÿåˆ / Fine fitting)
è¯¯å·® â‰¥ 5g â†’ |error| âˆ’ Î²/2      (çº¿æ€§ï¼ŒæŠ—æµ‹é‡å™ªå£° / Linear, noise-robust)
```

### 3. æ¢¯åº¦ç´¯ç§¯é€‚é…å¤§æ¨¡å‹ï¼ˆæ•´åˆç‰ˆï¼‰/ Gradient Accumulation for Large Models (Integrated)

æ¢¯åº¦ç´¯ç§¯ï¼ˆsteps=2ï¼‰åœ¨ä¸å¢åŠ æ˜¾å­˜çš„å‰æä¸‹å°†ç­‰æ•ˆ batch size ä» 6 æå‡è‡³ 12ï¼Œç¨³å®š ViT-Huge è®­ç»ƒï¼š

```python
for i, (left, right, labels) in enumerate(loader):
    with autocast():
        loss = criterion(model(left, right), labels) / accum_steps
    scaler.scale(loss).backward()
    if (i + 1) % accum_steps == 0:
        scaler.unscale_(optimizer)
        clip_grad_norm_(model.parameters(), 1.0)
        scaler.step(optimizer); scaler.update()
        optimizer.zero_grad(); scheduler.step()
```

### 4. åˆ†å±‚ + åˆ†ç»„ K æŠ˜ / Stratified + Grouped K-Fold

```python
sgkf = StratifiedGroupKFold(n_splits=4, shuffle=True, random_state=42)
df['total_bin'] = pd.qcut(df['Dry_Total_g'], q=5, labels=False, duplicates='drop')
# åˆ†å±‚ï¼šå„æŠ˜ Total ç”Ÿç‰©é‡åˆ†å¸ƒå‡è¡¡ / Balanced Total distribution across folds
# åˆ†ç»„ï¼šåŒä¸€å›¾åƒä¸è·¨æŠ˜ï¼Œé˜²æ­¢æ•°æ®æ³„æ¼ / Same image stays in same fold (no leakage)
```

### 5. YAML ç»Ÿä¸€é…ç½®ç®¡ç†ï¼ˆæ•´åˆç‰ˆæ–°å¢ï¼‰/ Unified YAML Config (New in Integrated)

```yaml
# config.yaml
data:
  image_size: 512
  split_mode: "left_right"          # left_right | sliding_window | multi_scale
model:
  dino:
    lr_backbone: 1e-5
    lr_head: 5e-4
    smooth_l1_beta: 5.0
    grad_accum_steps: 2
  siglip:
    patch_size: 520
    overlap: 16
    gbdt_models: ["lgbm", "catboost"]
fusion:
  weight_opt: true                  # true â†’ OOF è‡ªåŠ¨ä¼˜åŒ– / OOF auto-optimize
  base_weights: [0.7, 0.3]         # ç«èµ›ç‰ˆåˆå§‹å€¼ / Competition version init
post_process:
  auto_tune: true                   # true â†’ ç½‘æ ¼æœç´¢ / Grid search
  clover_scale_range: [0.70, 0.90]
  dead_threshold_candidates: [[8,18], [10,20], [12,22]]
```

---

## ğŸ“ ä»“åº“ç»“æ„ / Repository Structure

```
CSIRO-Image2Biomass/
â”‚
â”œâ”€â”€ README.md                       â† æœ¬æ–‡ä»¶ï¼ˆä¸­è‹±å¯¹ç…§ï¼‰/ This file (bilingual)
â”‚
â”œâ”€â”€ config.yaml                     â† ç»Ÿä¸€è¶…å‚é…ç½®ï¼ˆæ•´åˆç‰ˆæ–°å¢ï¼‰/ Unified config (new)
â”‚
â”œâ”€â”€ train.py                        â† DINOv3 4 æŠ˜è®­ç»ƒ + OOF è¾“å‡º
â”‚                                      4-fold training + OOF predictions output
â”‚
â”œâ”€â”€ optimize_fusion.py              â† OOF ä¼˜åŒ–èåˆæƒé‡ + åå¤„ç†å‚æ•°ï¼ˆæ•´åˆç‰ˆæ–°å¢ï¼‰
â”‚                                      OOF-based weight + post-processing optimization (new)
â”‚
â”œâ”€â”€ inference.py                    â† åŒè·¯æ¨ç† + è‡ªåŠ¨åŒ–åå¤„ç† + é›†æˆ â†’ submission.csv
â”‚                                      Two-route inference + auto post-processing + ensemble
â”‚
â””â”€â”€ outputs/                        â† ç”Ÿæˆäº§ç‰© (gitignored) / Generated outputs
    â”œâ”€â”€ fold{0..3}_best.pth         â† å„æŠ˜æœ€ä½³æƒé‡ / Best weights per fold
    â”œâ”€â”€ dino_oof.csv                â† DINO OOF é¢„æµ‹ï¼ˆæ•´åˆç‰ˆæ–°å¢ï¼‰/ DINO OOF predictions
    â”œâ”€â”€ siglip_oof.csv              â† SigLIP OOF é¢„æµ‹ï¼ˆæ•´åˆç‰ˆæ–°å¢ï¼‰/ SigLIP OOF predictions
    â”œâ”€â”€ best_params.json            â† æœ€ä¼˜èåˆæƒé‡ + åå¤„ç†å‚æ•° / Best params
    â”œâ”€â”€ training_summary.json       â† å„æŠ˜ CV RÂ² / Per-fold CV RÂ²
    â””â”€â”€ submission.csv              â† æœ€ç»ˆæäº¤ / Final submission
                                       ğŸ¥ˆ Rank 82 / 3802 Â· LB Weighted RÂ² = 0.64
```

### è„šæœ¬æ‰§è¡Œé¡ºåº / Execution Order

```
Step 1: train.py
   â”œâ”€â”€ è¯»å– config.yaml â†’ é…ç½®åˆ†å—æ¨¡å¼ã€ç‰©ç†çº¦æŸå¤´
   â”œâ”€â”€ 4 æŠ˜è®­ç»ƒï¼ˆå¯é…ç½®ç‰©ç†çº¦æŸå¤´ + Clover ä¸“é¡¹åˆ†æ”¯ï¼‰
   â”œâ”€â”€ ä¿å­˜ fold{k}_best.pth
   â””â”€â”€ è¾“å‡º dino_oof.csv + training_summary.json

Step 2: optimize_fusion.py  â†ã€æ•´åˆç‰ˆæ–°å¢ / Newã€‘
   â”œâ”€â”€ è¯»å– dino_oof.csv + siglip_oof.csv
   â”œâ”€â”€ scipy æ¢¯åº¦æœç´¢ â†’ æœ€ä¼˜ w_dino / w_siglip
   â”œâ”€â”€ ç½‘æ ¼æœç´¢åå¤„ç†å‚æ•°ï¼ˆClover_scale Â· Dead é˜ˆå€¼ï¼‰
   â””â”€â”€ ä¿å­˜ best_params.json

Step 3: inference.py
   â”œâ”€â”€ [1/6] åŠ è½½æµ‹è¯•æ•°æ®
   â”œâ”€â”€ [2/6] DINO 4 æŠ˜æ¨ç† â†’ æŠ˜å‡å€¼é›†æˆ
   â”œâ”€â”€ [3/6] è¯»å– best_params â†’ è‡ªåŠ¨åŒ–åå¤„ç†
   â”œâ”€â”€ [4/6] SigLIP åµŒå…¥ â†’ è‡ªåŠ¨æ‰©å±•è¯­ä¹‰ç‰¹å¾ â†’ è½»é‡ GBDTï¼ˆ2 æ¨¡å‹ï¼‰
   â”œâ”€â”€ [5/6] OOF ä¼˜åŒ–æƒé‡èåˆï¼ˆClover ä»… DINOï¼‰
   â””â”€â”€ [6/6] mass_balance_correction + éè´Ÿæˆªæ–­ â†’ submission.csv
```

---

## ğŸš€ å¤ç°æŒ‡å— / Reproduction Guide

### ç¯å¢ƒè¦æ±‚ / Environment Requirements

| é¡¹ç›® / Item | è¦æ±‚ / Requirement |
|---|---|
| **å¹³å° / Platform** | Kaggle Notebookï¼ˆGPU enabledï¼‰|
| **Python** | 3.10 |
| **GPU** | T4 / P100ï¼ˆâ‰¥16GB VRAM æ¨èï¼‰|
| **è¿è¡Œæ—¶é™ / Runtime** | â‰¤ 9 hï¼ˆæ•´åˆç‰ˆä¼˜åŒ–è‡³ ~7 hï¼Œé¢„ç•™ TTA ç©ºé—´ï¼‰|

### æ ¸å¿ƒä¾èµ– / Key Dependencies

```
torch >= 2.0
timm                    # vit_huge_plus_patch16_dinov3
albumentations          # å›¾åƒå¢å¼º
transformers            # SigLIP (google/siglip-so400m-patch14-384)
lightgbm, catboost
scikit-learn            # PCA, PLS, GMM, StratifiedGroupKFold
scipy                   # èåˆæƒé‡ä¼˜åŒ–ï¼ˆæ•´åˆç‰ˆæ–°å¢ï¼‰/ Fusion weight optimization (new)
mlflow                  # è®­ç»ƒæ—¥å¿—ï¼ˆæ•´åˆç‰ˆæ–°å¢ï¼‰/ Training logging (new)
googletrans             # è¯­ä¹‰ prompt æ‰©å±•ï¼ˆæ•´åˆç‰ˆæ–°å¢ï¼‰/ Semantic prompt expansion (new)
pandas, numpy, opencv-python, pillow, tqdm, pyyaml
```

### Kaggle Dataset é…ç½® / Required Kaggle Datasets

| Dataset | ç”¨é€” / Purpose |
|---|---|
| `csiro-biomass` | æ¯”èµ›å®˜æ–¹æ•°æ®ï¼ˆå›¾åƒ + CSVï¼‰/ Official competition data |
| `dino-huge-retrain-checkpoints-zul` | å·²è®­ç»ƒ 4 æŠ˜ DINO æƒé‡ï¼ˆæ¨ç†ç”¨ï¼‰/ Trained 4-fold DINO weights |
| `google-siglip-so400m-patch14-384` | SigLIP é¢„è®­ç»ƒæƒé‡ / SigLIP pretrained weights |
| `csiro-datasplit` | å« fold æ ‡è®°çš„è®­ç»ƒåˆ’åˆ† CSV / Training split with fold labels |

### æ“ä½œæ­¥éª¤ / Step-by-Step

```
1. åœ¨ Kaggle æ–°å»º Notebookï¼Œæ·»åŠ ä¸Šè¿°æ‰€æœ‰æ•°æ®é›†
   Create a Kaggle Notebook, add all datasets above

2. ç¼–è¾‘ config.yamlï¼šé€‰æ‹©åˆ†å—æ¨¡å¼ï¼ˆsplit_modeï¼‰ã€æ˜¯å¦è‡ªåŠ¨ä¼˜åŒ–ï¼ˆweight_opt / auto_tuneï¼‰
   Edit config.yaml: select split mode, enable auto-optimization flags

3. è¿è¡Œ train.pyï¼ˆé‡è®­ç»ƒæ—¶ï¼›æ¨ç†å¯ç›´æ¥ä½¿ç”¨å·²å‘å¸ƒæƒé‡ï¼‰
   Run train.py (if retraining; for inference, use published checkpoint weights)
     â†’ fold{0..3}_best.pth + dino_oof.csv + training_summary.json

4. è¿è¡Œ optimize_fusion.pyï¼ˆæ•´åˆç‰ˆæ–°å¢æ­¥éª¤ï¼‰
   Run optimize_fusion.py (new step in integrated version)
     â†’ best_params.jsonï¼ˆæœ€ä¼˜èåˆæƒé‡ + æœ€ä¼˜åå¤„ç†å‚æ•°ï¼‰

5. è¿è¡Œ inference.py
   Run inference.py
     â†’ è‡ªåŠ¨è¯»å– best_params â†’ åŒè·¯æ¨ç† â†’ èåˆ â†’ submission.csv

6. æäº¤ submission.csv åˆ°æ¯”èµ›é¡µ
   Submit submission.csv to the competition page
```

---

## ğŸ“ åæ€ä¸æœªæ¥æ–¹å‘ / Reflections & Future Directions

### æ–¹æ³•è®ºåæ€ / Methodological Reflections

**1. ç‰©ç†çº¦æŸç¡¬ç¼–ç æ˜¯ Total é«˜æƒé‡åœºæ™¯çš„æœ€ä¼˜è§£ / Hard-coded physics constraints are optimal for high-weight Total**

Total æƒé‡é«˜è¾¾ 0.5ï¼Œä»»ä½•"ç‹¬ç«‹å›å½’ä½†ç‰©ç†ä¸ä¸€è‡´"çš„é¢„æµ‹éƒ½ç›´æ¥æ‹–ç´¯æœ€ç»ˆåˆ†æ•°ã€‚å°† GDM / Total è®¾ä¸ºæ´¾ç”Ÿé‡è€Œéç‹¬ç«‹ç›®æ ‡ï¼Œæ˜¯æœ¬æ–¹æ¡ˆåœ¨ 3802 æ”¯é˜Ÿä¼ä¸­æ’åç¬¬ 82 çš„æ ¸å¿ƒæ¶æ„å†³ç­–ã€‚æ•´åˆç‰ˆè¿›ä¸€æ­¥å°†è¿™ä¸€æ€è·¯æ³›åŒ–ä¸ºå¯é…ç½®æ¨¡å—ï¼Œé€‚é…ä»»æ„ç‰©ç†çº¦æŸåœºæ™¯ã€‚

With Total weighted at 0.5, any "independently regressed but physically inconsistent" prediction directly hurts the final score. Making GDM / Total derived quantities rather than independent targets is one of the core architectural decisions behind Rank 82 / 3802. The integrated version further generalizes this into a configurable module for any physics-constraint scenario.

**2. è‡ªåŠ¨åŒ–æ›¿ä»£ç»éªŒçš„è¾¹é™…ä»·å€¼ / Marginal value of automation over heuristics**

é“¶ç‰Œæ–¹æ¡ˆä¸­æ‰‹åŠ¨è®¾å®šçš„åå¤„ç†å‚æ•°ï¼ˆCloverÃ—0.8ã€Dead é˜ˆå€¼ï¼‰æ˜¯åŸºäºæœ‰é™éªŒè¯çš„ç»éªŒå€¼ï¼Œå­˜åœ¨å› ç»éªŒå€¼ä¸å‡†ç¡®å¸¦æ¥çš„é£é™©ã€‚æ•´åˆç‰ˆé€šè¿‡ OOF ç½‘æ ¼æœç´¢ç³»ç»ŸåŒ–æ¢ç´¢å‚æ•°ç©ºé—´ï¼Œåœ¨æ¶ˆé™¤ä¸ç¡®å®šæ€§çš„åŒæ—¶é¢„æœŸè¿›ä¸€æ­¥æå‡åˆ†æ•°ã€‚

The Silver Medal solution's manually set post-processing parameters were empirically derived from limited validation, carrying risks from inaccurate heuristics. The integrated version systematically explores the parameter space via OOF grid search, eliminating uncertainty while expected to further improve the score.

**3. è¿è¡Œæ—¶é—´çº¦æŸå€’é€¼æ¶æ„ç®€åŒ– / Runtime constraints force architectural simplification**

Kaggle 9 å°æ—¶é™åˆ¶æ˜¯æ‰€æœ‰å·¥ç¨‹å†³ç­–çš„éšæ€§çº¦æŸã€‚GBDT ä» 4 æ¨¡å‹ç²¾ç®€ä¸º 2 æ¨¡å‹ã€æ¢¯åº¦ç´¯ç§¯æ›¿ä»£æ›´å¤§ batchã€æ—©åœæå‰æˆªæ–­â€”â€”æ¯ä¸ªå†³ç­–èƒŒåéƒ½æœ‰è¿è¡Œæ—¶é—´çš„è€ƒé‡ã€‚è¿™æé†’æˆ‘ä»¬ï¼šèµ„æºå—é™åœºæ™¯ä¸‹ï¼Œ"è¶³å¤Ÿå¥½"çš„è½»é‡åŒ–æ–¹æ¡ˆå¾€å¾€ä¼˜äº"æœ€ä¼˜"çš„é‡å‹æ–¹æ¡ˆã€‚

Kaggle's 9-hour limit is the implicit constraint behind all engineering decisions. Reducing GBDT from 4 to 2 models, gradient accumulation replacing larger batches, early stopping â€” each driven by runtime considerations. This reminds us that in resource-constrained settings, a "good enough" lightweight solution often beats the "optimal" heavyweight one.

### æ˜ç¡®ä¸è¶³ / Known Limitations

| ä¸è¶³ / Limitation | ç«èµ›ç‰ˆ / Competition | æ•´åˆç‰ˆæ”¹å–„ / Optimized Improvement |
|---|---|---|
| **èåˆæƒé‡æœªä¼˜åŒ–** | æ‰‹åŠ¨ 0.7/0.3 | âœ… OOF æ¢¯åº¦æœç´¢è‡ªåŠ¨åŒ– |
| **åå¤„ç†å‚æ•°ç»éªŒæ€§** | CloverÃ—0.8 å›ºå®š | âœ… ç½‘æ ¼æœç´¢ [0.70, 0.90] |
| **Clover ä»æ˜¯ç“¶é¢ˆ** | ç³»ç»Ÿæ€§é«˜ä¼° | âš¡ ä¸“é¡¹åˆ†æ”¯æ”¹å–„ï¼Œä»æ˜¯æœ€éš¾ç›®æ ‡ |
| **OOF èåˆè¯„ä¼°ç¼ºå¤±** | æ—  | âœ… å…¨æµç¨‹ OOF éªŒè¯ |
| **è¿è¡Œæ—¶é—´ç´§å¼ ** | æ¥è¿‘ 9 å°æ—¶ | âœ… ä¼˜åŒ–è‡³ ~7 å°æ—¶ |
| **å¤šå°ºåº¦ TTA** | æœªå®æ–½ | âš¡ é¢„ç•™ç©ºé—´ï¼Œå¾…å®æ–½ |

### æœªæ¥æ‹“å±•æ–¹å‘ / Future Directions

1. **TTA è‡ªåŠ¨åŒ– / Automated TTA** â€” æ¨ç†æ—¶æ°´å¹³ç¿»è½¬ + å¤šå°ºåº¦ï¼Œè‡ªåŠ¨é€‰æ‹©æœ€ä¼˜èåˆç­–ç•¥ï¼Œé¢„è®¡åœ¨æ•´åˆç‰ˆåŸºç¡€ä¸Šå†æå‡ã€‚
2. **è·¨åœºæ™¯è¿ç§»å¥—ä»¶ / Cross-scene transfer toolkit** â€” å°è£…ã€Œå¯é…ç½®ç‰©ç†çº¦æŸå¤´ã€ã€Œå®½å¹…åˆ†å—ã€ã€ŒåŒè·¯èåˆ + OOF ä¼˜åŒ–ã€ä¸ºé€šç”¨å·¥å…·åŒ…ï¼Œé€‚é…å«æ˜Ÿå›¾åƒ / å·¥ä¸šè´¨æ£€ç­‰å›å½’åœºæ™¯ã€‚
3. **Clover å¤šæ¨¡æ€ç‰¹å¾ / Clover multi-modal features** â€” å¼•å…¥ NDVI å’Œ Height_Ave_cm ç­‰ç»“æ„åŒ–ç‰¹å¾ä½œä¸º Clover ä¸“é¡¹åˆ†æ”¯çš„è¾…åŠ©è¾“å…¥ï¼Œå¼¥è¡¥çº¯è§†è§‰ä¿¡å·çš„ä¸è¶³ã€‚
4. **æ¨¡å‹è’¸é¦ / Model distillation** â€” å°† ViT-Huge è’¸é¦ä¸º ViT-Smallï¼Œé€‚é…ä½ç®—åŠ›æˆ–å®æ—¶æ¨ç†åœºæ™¯ã€‚
5. **Stacking æ›¿ä»£ Blending / Stacking over blending** â€” ç”¨åŒè·¯ OOF é¢„æµ‹è®­ç»ƒå…ƒå­¦ä¹ å™¨ï¼Œæ›¿ä»£å½“å‰çš„çº¿æ€§åŠ æƒèåˆã€‚

---

## ğŸ›  æŠ€æœ¯æ ˆ / Tech Stack

| ç±»åˆ« / Category | å·¥å…· / Tools | æ•´åˆç‰ˆæ–°å¢ / New in Optimized |
|---|---|---|
| æ·±åº¦å­¦ä¹  / Deep Learning | PyTorch 2.x, timm | å¯é…ç½®ç‰©ç†çº¦æŸå¤´ï¼ŒClover ä¸“é¡¹åˆ†æ”¯ |
| è§†è§‰-è¯­è¨€æ¨¡å‹ / VLM | Transformers (SigLIP) | è‡ªåŠ¨ prompt æ‰©å±•ï¼ˆgoogletransï¼‰|
| æ¢¯åº¦æå‡ / Gradient Boosting | LightGBM, CatBoost | OOF åŠ æƒèåˆï¼Œè½»é‡åŒ–ï¼ˆ4â†’2 æ¨¡å‹ï¼‰|
| ä¼˜åŒ–å·¥å…· / Optimization | â€” | scipy.optimizeï¼ˆèåˆæƒé‡ï¼‰ï¼Œç½‘æ ¼æœç´¢ï¼ˆåå¤„ç†ï¼‰|
| ç‰¹å¾å·¥ç¨‹ / Feature Engineering | scikit-learn (PCA, PLS, GMM) | å¯é…ç½®é™ç»´æ–¹æ³•ï¼ˆTSNE / UMAPï¼‰|
| å›¾åƒå¤„ç† / Image Processing | Albumentations, OpenCV, Pillow | å¤šå°ºåº¦éšæœºåˆ†è¾¨ç‡è®­ç»ƒ |
| å·¥ç¨‹åŒ– / Engineering | â€” | MLflow æ—¥å¿—ï¼ŒYAML ç»Ÿä¸€é…ç½® |
| æ•°æ®å¤„ç† / Data | Pandas, NumPy | â€” |
| è¿è¡Œç¯å¢ƒ / Environment | Kaggle Notebooks (T4/P100, 9h) | ä¼˜åŒ–è‡³ ~7hï¼Œé¢„ç•™ TTA ç©ºé—´ |

---

<div align="center">

**ğŸ¥ˆ Kaggle Silver Medal Â· Rank 82 / 3802 Â· Top 2.2%**

**LB Weighted RÂ² = 0.64ï¼ˆç«èµ›è½åœ°ç‰ˆï¼‰â†’ 0.65+ï¼ˆæ•´åˆä¼˜åŒ–ç‰ˆé¢„æœŸï¼‰**

*æœ¬æ–¹æ¡ˆåœ¨ 3802 æ”¯å‚èµ›é˜Ÿä¼ä¸­æ’åç¬¬ 82ï¼Œä½åˆ—å‰ 2.2%ï¼Œæ–©è· Kaggle é“¶ç‰Œã€‚*

*This solution ranked 82nd among 3,802 teams (Top 2.2%), earning a Kaggle Silver Medal.*

</div>

---

*ä»“åº“ä»£ç ä¸è¯´æ˜ä»…ä¾›å­¦ä¹ äº¤æµï¼Œéµå¾ª MIT åè®®ã€‚/ For educational and research purposes, licensed under MIT.*
